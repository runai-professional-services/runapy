# coding: utf-8

"""
NVIDIA Run:ai

# Introduction  The NVIDIA Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  NVIDIA Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create a **Service account** through the NVIDIA Run:ai user interface. To create a service account, in your UI, go to Access → Service Accounts (for organization-level service accounts) or User settings → Access Keys (for user access keys), and create a new one.  After you have created a new service account, you will need to assign it access rules. To assign access rules to the service account, see [Create access rules](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/accessrules#create-or-delete-rules). Make sure you assign the correct rules to your service account. Use the [Roles](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://run-ai-docs.nvidia.com/saas/reference/api/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from runai.models.auto_scaling import AutoScaling
from runai.models.environment_variable import EnvironmentVariable
from runai.models.image_pull_policy import ImagePullPolicy
from runai.models.image_pull_secret import ImagePullSecret
from runai.models.node_affinity_required import NodeAffinityRequired
from runai.models.pod_affinity import PodAffinity
from runai.models.preemptibility import Preemptibility
from runai.models.probes import Probes
from runai.models.serving_configuration import ServingConfiguration
from runai.models.superset_spec_all_of_compute import SupersetSpecAllOfCompute
from typing import Optional, Set
from typing_extensions import Self


class InferenceUpdateSpecSpec(BaseModel):
    """
    Pydantic class model representing InferenceUpdateSpecSpec.

    Parameters:
        ```python
        autoscaling: Optional[AutoScaling]
        serving_configuration: Optional[ServingConfiguration]
        args: Optional[str]
        category: Optional[str]
        command: Optional[str]
        compute: Optional[SupersetSpecAllOfCompute]
        create_home_dir: Optional[bool]
        environment_variables: Optional[List[EnvironmentVariable]]
        image: Optional[str]
        image_pull_policy: Optional[ImagePullPolicy]
        image_pull_secrets: Optional[List[ImagePullSecret]]
        node_affinity_required: Optional[NodeAffinityRequired]
        node_pools: Optional[List[str]]
        node_type: Optional[str]
        pod_affinity: Optional[PodAffinity]
        preemptibility: Optional[Preemptibility]
        priority_class: Optional[str]
        probes: Optional[Probes]
        working_dir: Optional[str]
        ```
        autoscaling: See model AutoScaling for more information.
        serving_configuration: See model ServingConfiguration for more information.
        args: Arguments to the command that the container running the workload executes.
        category: Specify the workload category assigned to the workload. Categories are used to classify and monitor different types of workloads within the NVIDIA Run:ai platform.
        command: A command to the server as the entry point of the container running the workload.
        compute: See model SupersetSpecAllOfCompute for more information.
        create_home_dir: When set to &#x60;true&#x60;, creates a home directory for the container.
        environment_variables: Set of environment variables to populate into the container running the workload.
        image: Docker image name. For more information, see [Images](https://kubernetes.io/docs/concepts/containers/images). The image name is mandatory for creating a workload.
        image_pull_policy: See model ImagePullPolicy for more information.
        image_pull_secrets: A list of references to Kubernetes secrets in the same namespace used for pulling container images.
        node_affinity_required: See model NodeAffinityRequired for more information.
        node_pools: A prioritized list of node pools for the scheduler to run the workload on. The scheduler will always try to use the first node pool before moving to the next one if the first is not available.
        node_type: Nodes (machines), or a group of nodes on which the workload will run. To use this feature, your Administrator will need to label nodes. For more information, see [Group Nodes](https://docs.run.ai/latest/admin/researcher-setup/limit-to-node-group). When using this flag with with Project-based affinity, it refines the list of allowable node groups set in the Project. For more information, see [Projects](https://docshub.run.ai/guides/platform-management/aiinitiatives/organization/projects).
        pod_affinity: See model PodAffinity for more information.
        preemptibility: See model Preemptibility for more information.
        priority_class: Specifies the priority class for the workload, which determines its scheduling behavior. Valid values are: very-low, low, medium-low, medium, medium-high, high, and very-high. Each workload type has a default priority. To view the default priority for each workload type, use the GET /workload-types endpoint. Once you change the priority from the default value defined for that workload type, the preemptibility field is not automatically updated. Make sure to set the desired preemptibility value.
        probes: See model Probes for more information.
        working_dir: Container&#39;s working directory. If not specified, the container runtime default will be used. This may be configured in the container image.
    Example:
        ```python
        InferenceUpdateSpecSpec(
            autoscaling=runai.models.auto_scaling.AutoScaling(),
                        serving_configuration=runai.models.serving_configuration.ServingConfiguration(
                    initialization_timeout_seconds = 1,
                    request_timeout_seconds = 1, ),
                        args='-x my-script.py',
                        category='jUR,rZ#UM/?R,Fp^l6$ARj',
                        command='python',
                        compute=runai.models.superset_spec_all_of_compute.SupersetSpec_allOf_compute(
                    cpu_core_limit = 2,
                    cpu_core_request = 0.5,
                    cpu_memory_limit = '30M',
                    cpu_memory_request = '20M',
                    extended_resources = [
                        runai.models.extended_resource.ExtendedResource(
                            resource = 'hardware-vendor.example/foo',
                            quantity = '2',
                            exclude = False, )
                        ],
                    gpu_devices_request = 1,
                    gpu_memory_limit = '10M',
                    gpu_memory_request = '10M',
                    gpu_portion_limit = 0.5,
                    gpu_portion_request = 0.5,
                    gpu_request_type = 'portion',
                    large_shm_request = False, ),
                        create_home_dir=True,
                        environment_variables=[
                    runai.models.environment_variable.EnvironmentVariable(
                        name = 'HOME',
                        value = '/home/my-folder',
                        secret = runai.models.environment_variable_secret.EnvironmentVariableSecret(
                            name = 'postgress_secret',
                            key = 'POSTGRES_PASSWORD', ),
                        config_map = runai.models.environment_variable_config_map.EnvironmentVariableConfigMap(
                            name = 'my-config-map',
                            key = 'MY_POSTGRES_SCHEMA', ),
                        pod_field_ref = runai.models.environment_variable_pod_field_reference.EnvironmentVariablePodFieldReference(
                            path = 'metadata.name', ),
                        user_credential = runai.models.environment_variable_user_credential.EnvironmentVariableUserCredential(
                            name = 'my_postgres_user_and_password',
                            key = 'POSTGRES_PASSWORD', ),
                        exclude = False,
                        description = 'Home directory of the user.', )
                    ],
                        image='python:3.8',
                        image_pull_policy='Always',
                        image_pull_secrets=[
                    runai.models.image_pull_secret.ImagePullSecret(
                        name = 'w1c2v7s6djuy1zmetozkhdomha1bae37b8ocvx8o53ow2eg7p6qw9qklp6l4y010fogx',
                        user_credential = True,
                        exclude = False, )
                    ],
                        node_affinity_required=runai.models.node_affinity_required.NodeAffinityRequired(
                    node_selector_terms = [
                        runai.models.node_selector_term.NodeSelectorTerm(
                            match_expressions = [
                                runai.models.match_expression.MatchExpression(
                                    key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                                    operator = 'In',
                                    values = [
                                        'jUR,rZ#UM/?R,Fp^l6$ARj'
                                        ], )
                                ], )
                        ], ),
                        node_pools=["my-node-pool-a","my-node-pool-b"],
                        node_type='my-node-type',
                        pod_affinity=runai.models.pod_affinity.PodAffinity(
                    type = 'Required',
                    key = 'jUR,rZ#UM/?R,Fp^l6$ARj', ),
                        preemptibility='preemptible',
                        priority_class='jUR,rZ#UM/?R,Fp^l6$ARj',
                        probes=runai.models.probes.Probes(
                    readiness = runai.models.probe.Probe(
                        initial_delay_seconds = 0,
                        period_seconds = 1,
                        timeout_seconds = 1,
                        success_threshold = 1,
                        failure_threshold = 1,
                        handler = runai.models.probe_handler.ProbeHandler(
                            http_get = runai.models.probe_handler_http_get.ProbeHandler_httpGet(
                                path = '/',
                                port = 1,
                                host = 'example.com',
                                scheme = 'HTTP', ), ), ), ),
                        working_dir='/home/myfolder'
        )
        ```
    """  # noqa: E501

    autoscaling: Optional[AutoScaling] = None
    serving_configuration: Optional[ServingConfiguration] = Field(
        default=None, alias="servingConfiguration"
    )
    args: Optional[Annotated[str, Field(min_length=1, strict=True)]] = Field(
        default=None,
        description="Arguments to the command that the container running the workload executes.",
    )
    category: Optional[Annotated[str, Field(strict=True)]] = Field(
        default=None,
        description="Specify the workload category assigned to the workload. Categories are used to classify and monitor different types of workloads within the NVIDIA Run:ai platform.",
    )
    command: Optional[Annotated[str, Field(min_length=1, strict=True)]] = Field(
        default=None,
        description="A command to the server as the entry point of the container running the workload.",
    )
    compute: Optional[SupersetSpecAllOfCompute] = None
    create_home_dir: Optional[StrictBool] = Field(
        default=None,
        description="When set to `true`, creates a home directory for the container.",
        alias="createHomeDir",
    )
    environment_variables: Optional[List[Optional[EnvironmentVariable]]] = Field(
        default=None,
        description="Set of environment variables to populate into the container running the workload.",
        alias="environmentVariables",
    )
    image: Optional[Annotated[str, Field(min_length=1, strict=True)]] = Field(
        default=None,
        description="Docker image name. For more information, see [Images](https://kubernetes.io/docs/concepts/containers/images). The image name is mandatory for creating a workload.",
    )
    image_pull_policy: Optional[ImagePullPolicy] = Field(
        default=None, alias="imagePullPolicy"
    )
    image_pull_secrets: Optional[List[Optional[ImagePullSecret]]] = Field(
        default=None,
        description="A list of references to Kubernetes secrets in the same namespace used for pulling container images.",
        alias="imagePullSecrets",
    )
    node_affinity_required: Optional[NodeAffinityRequired] = Field(
        default=None, alias="nodeAffinityRequired"
    )
    node_pools: Optional[List[Annotated[str, Field(strict=True)]]] = Field(
        default=None,
        description="A prioritized list of node pools for the scheduler to run the workload on. The scheduler will always try to use the first node pool before moving to the next one if the first is not available.",
        alias="nodePools",
    )
    node_type: Optional[Annotated[str, Field(min_length=1, strict=True)]] = Field(
        default=None,
        description="Nodes (machines), or a group of nodes on which the workload will run. To use this feature, your Administrator will need to label nodes. For more information, see [Group Nodes](https://docs.run.ai/latest/admin/researcher-setup/limit-to-node-group). When using this flag with with Project-based affinity, it refines the list of allowable node groups set in the Project. For more information, see [Projects](https://docshub.run.ai/guides/platform-management/aiinitiatives/organization/projects).",
        alias="nodeType",
    )
    pod_affinity: Optional[PodAffinity] = Field(default=None, alias="podAffinity")
    preemptibility: Optional[Preemptibility] = None
    priority_class: Optional[Annotated[str, Field(strict=True)]] = Field(
        default=None,
        description="Specifies the priority class for the workload, which determines its scheduling behavior. Valid values are: very-low, low, medium-low, medium, medium-high, high, and very-high. Each workload type has a default priority. To view the default priority for each workload type, use the GET /workload-types endpoint. Once you change the priority from the default value defined for that workload type, the preemptibility field is not automatically updated. Make sure to set the desired preemptibility value.",
        alias="priorityClass",
    )
    probes: Optional[Probes] = None
    working_dir: Optional[Annotated[str, Field(min_length=1, strict=True)]] = Field(
        default=None,
        description="Container's working directory. If not specified, the container runtime default will be used. This may be configured in the container image.",
        alias="workingDir",
    )
    __properties: ClassVar[List[str]] = [
        "autoscaling",
        "servingConfiguration",
        "args",
        "category",
        "command",
        "compute",
        "createHomeDir",
        "environmentVariables",
        "image",
        "imagePullPolicy",
        "imagePullSecrets",
        "nodeAffinityRequired",
        "nodePools",
        "nodeType",
        "podAffinity",
        "preemptibility",
        "priorityClass",
        "probes",
        "workingDir",
    ]

    @field_validator("args")
    def args_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("category")
    def category_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("command")
    def command_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("image")
    def image_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("node_type")
    def node_type_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("priority_class")
    def priority_class_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("working_dir")
    def working_dir_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of InferenceUpdateSpecSpec from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of autoscaling
        if self.autoscaling:
            _dict["autoscaling"] = self.autoscaling.to_dict()
        # override the default output from pydantic by calling `to_dict()` of serving_configuration
        if self.serving_configuration:
            _dict["servingConfiguration"] = self.serving_configuration.to_dict()
        # override the default output from pydantic by calling `to_dict()` of compute
        if self.compute:
            _dict["compute"] = self.compute.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in environment_variables (list)
        _items = []
        if self.environment_variables:
            for _item_environment_variables in self.environment_variables:
                if _item_environment_variables:
                    _items.append(_item_environment_variables.to_dict())
            _dict["environmentVariables"] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in image_pull_secrets (list)
        _items = []
        if self.image_pull_secrets:
            for _item_image_pull_secrets in self.image_pull_secrets:
                if _item_image_pull_secrets:
                    _items.append(_item_image_pull_secrets.to_dict())
            _dict["imagePullSecrets"] = _items
        # override the default output from pydantic by calling `to_dict()` of node_affinity_required
        if self.node_affinity_required:
            _dict["nodeAffinityRequired"] = self.node_affinity_required.to_dict()
        # override the default output from pydantic by calling `to_dict()` of pod_affinity
        if self.pod_affinity:
            _dict["podAffinity"] = self.pod_affinity.to_dict()
        # override the default output from pydantic by calling `to_dict()` of probes
        if self.probes:
            _dict["probes"] = self.probes.to_dict()
        # set to None if autoscaling (nullable) is None
        # and model_fields_set contains the field
        if self.autoscaling is None and "autoscaling" in self.model_fields_set:
            _dict["autoscaling"] = None

        # set to None if serving_configuration (nullable) is None
        # and model_fields_set contains the field
        if (
            self.serving_configuration is None
            and "serving_configuration" in self.model_fields_set
        ):
            _dict["servingConfiguration"] = None

        # set to None if args (nullable) is None
        # and model_fields_set contains the field
        if self.args is None and "args" in self.model_fields_set:
            _dict["args"] = None

        # set to None if category (nullable) is None
        # and model_fields_set contains the field
        if self.category is None and "category" in self.model_fields_set:
            _dict["category"] = None

        # set to None if command (nullable) is None
        # and model_fields_set contains the field
        if self.command is None and "command" in self.model_fields_set:
            _dict["command"] = None

        # set to None if compute (nullable) is None
        # and model_fields_set contains the field
        if self.compute is None and "compute" in self.model_fields_set:
            _dict["compute"] = None

        # set to None if create_home_dir (nullable) is None
        # and model_fields_set contains the field
        if self.create_home_dir is None and "create_home_dir" in self.model_fields_set:
            _dict["createHomeDir"] = None

        # set to None if environment_variables (nullable) is None
        # and model_fields_set contains the field
        if (
            self.environment_variables is None
            and "environment_variables" in self.model_fields_set
        ):
            _dict["environmentVariables"] = None

        # set to None if image (nullable) is None
        # and model_fields_set contains the field
        if self.image is None and "image" in self.model_fields_set:
            _dict["image"] = None

        # set to None if image_pull_policy (nullable) is None
        # and model_fields_set contains the field
        if (
            self.image_pull_policy is None
            and "image_pull_policy" in self.model_fields_set
        ):
            _dict["imagePullPolicy"] = None

        # set to None if image_pull_secrets (nullable) is None
        # and model_fields_set contains the field
        if (
            self.image_pull_secrets is None
            and "image_pull_secrets" in self.model_fields_set
        ):
            _dict["imagePullSecrets"] = None

        # set to None if node_affinity_required (nullable) is None
        # and model_fields_set contains the field
        if (
            self.node_affinity_required is None
            and "node_affinity_required" in self.model_fields_set
        ):
            _dict["nodeAffinityRequired"] = None

        # set to None if node_pools (nullable) is None
        # and model_fields_set contains the field
        if self.node_pools is None and "node_pools" in self.model_fields_set:
            _dict["nodePools"] = None

        # set to None if node_type (nullable) is None
        # and model_fields_set contains the field
        if self.node_type is None and "node_type" in self.model_fields_set:
            _dict["nodeType"] = None

        # set to None if pod_affinity (nullable) is None
        # and model_fields_set contains the field
        if self.pod_affinity is None and "pod_affinity" in self.model_fields_set:
            _dict["podAffinity"] = None

        # set to None if preemptibility (nullable) is None
        # and model_fields_set contains the field
        if self.preemptibility is None and "preemptibility" in self.model_fields_set:
            _dict["preemptibility"] = None

        # set to None if priority_class (nullable) is None
        # and model_fields_set contains the field
        if self.priority_class is None and "priority_class" in self.model_fields_set:
            _dict["priorityClass"] = None

        # set to None if probes (nullable) is None
        # and model_fields_set contains the field
        if self.probes is None and "probes" in self.model_fields_set:
            _dict["probes"] = None

        # set to None if working_dir (nullable) is None
        # and model_fields_set contains the field
        if self.working_dir is None and "working_dir" in self.model_fields_set:
            _dict["workingDir"] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of InferenceUpdateSpecSpec from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "autoscaling": (
                    AutoScaling.from_dict(obj["autoscaling"])
                    if obj.get("autoscaling") is not None
                    else None
                ),
                "servingConfiguration": (
                    ServingConfiguration.from_dict(obj["servingConfiguration"])
                    if obj.get("servingConfiguration") is not None
                    else None
                ),
                "args": obj.get("args"),
                "category": obj.get("category"),
                "command": obj.get("command"),
                "compute": (
                    SupersetSpecAllOfCompute.from_dict(obj["compute"])
                    if obj.get("compute") is not None
                    else None
                ),
                "createHomeDir": obj.get("createHomeDir"),
                "environmentVariables": (
                    [
                        EnvironmentVariable.from_dict(_item)
                        for _item in obj["environmentVariables"]
                    ]
                    if obj.get("environmentVariables") is not None
                    else None
                ),
                "image": obj.get("image"),
                "imagePullPolicy": obj.get("imagePullPolicy"),
                "imagePullSecrets": (
                    [
                        ImagePullSecret.from_dict(_item)
                        for _item in obj["imagePullSecrets"]
                    ]
                    if obj.get("imagePullSecrets") is not None
                    else None
                ),
                "nodeAffinityRequired": (
                    NodeAffinityRequired.from_dict(obj["nodeAffinityRequired"])
                    if obj.get("nodeAffinityRequired") is not None
                    else None
                ),
                "nodePools": obj.get("nodePools"),
                "nodeType": obj.get("nodeType"),
                "podAffinity": (
                    PodAffinity.from_dict(obj["podAffinity"])
                    if obj.get("podAffinity") is not None
                    else None
                ),
                "preemptibility": obj.get("preemptibility"),
                "priorityClass": obj.get("priorityClass"),
                "probes": (
                    Probes.from_dict(obj["probes"])
                    if obj.get("probes") is not None
                    else None
                ),
                "workingDir": obj.get("workingDir"),
            }
        )
        return _obj
