# coding: utf-8

"""
NVIDIA Run:ai

# Introduction  The NVIDIA Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  NVIDIA Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create a **Service account** through the NVIDIA Run:ai user interface. To create a service account, in your UI, go to Access → Service Accounts (for organization-level service accounts) or User settings → Access Keys (for user access keys), and create a new one.  After you have created a new service account, you will need to assign it access rules. To assign access rules to the service account, see [Create access rules](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/accessrules#create-or-delete-rules). Make sure you assign the correct rules to your service account. Use the [Roles](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://run-ai-docs.nvidia.com/saas/reference/api/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field
from typing import Any, ClassVar, Dict, List, Optional
from runai.models.distributed_inference_leader_worker_rules_v2 import (
    DistributedInferenceLeaderWorkerRulesV2,
)
from typing import Optional, Set
from typing_extensions import Self


class DistributedInferenceWorkerRules(BaseModel):
    """
    Pydantic class model representing DistributedInferenceWorkerRules.

    Parameters:
        ```python
        worker: Optional[DistributedInferenceLeaderWorkerRulesV2]
        ```
        worker: Defines the pod specification for the workers. Required only if the number of workers is greater than 0.
    Example:
        ```python
        DistributedInferenceWorkerRules(
            worker=runai.models.distributed_inference_leader_worker_rules_v2.DistributedInferenceLeaderWorkerRulesV2(
                    annotations = runai.models.instances_rules.InstancesRules(
                        instances = runai.models.item_rules.ItemRules(
                            source_of_rule = {"scope":"project","projectId":3},
                            can_add = True,
                            locked = ["HOME","USER"], ), ),
                    args = runai.models.string_rules.StringRules(),
                    command = runai.models.string_rules.StringRules(),
                    compute = runai.models.superset_rules_all_of_compute.SupersetRules_allOf_compute(
                        cpu_core_limit = runai.models.number_rules.NumberRules(
                            required = True,
                            can_edit = True,
                            min = 1.337,
                            max = 1.337,
                            step = 1.337,
                            default_from = runai.models.default_from_rule.DefaultFromRule(
                                field = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                                factor = 1.337, ), ),
                        cpu_core_request = runai.models.number_rules.NumberRules(
                            required = True,
                            can_edit = True,
                            min = 1.337,
                            max = 1.337,
                            step = 1.337, ),
                        cpu_memory_limit = runai.models.quantity_rules.QuantityRules(
                            required = True,
                            can_edit = True,
                            min = '+0..1.73182.66.03300982804.9021169267472mmMGGmuikTPEPmTGiGkePiGemGmmnmeiniPPkTPnEePKmnuuEinuiGEEuiGuMETMPTPmeeKPenkETmEkMikEe-521919116647837856387556598',
                            max = '+0..1.73182.66.03300982804.9021169267472mmMGGmuikTPEPmTGiGkePiGemGmmnmeiniPPkTPnEePKmnuuEinuiGEEuiGuMETMPTPmeeKPenkETmEkMikEe-521919116647837856387556598', ),
                        cpu_memory_request = runai.models.quantity_rules.QuantityRules(
                            required = True,
                            can_edit = True,
                            min = '+0..1.73182.66.03300982804.9021169267472mmMGGmuikTPEPmTGiGkePiGemGmmnmeiniPPkTPnEePKmnuuEinuiGEEuiGuMETMPTPmeeKPenkETmEkMikEe-521919116647837856387556598',
                            max = '+0..1.73182.66.03300982804.9021169267472mmMGGmuikTPEPmTGiGkePiGemGmmnmeiniPPkTPnEePKmnuuEinuiGEEuiGuMETMPTPmeeKPenkETmEkMikEe-521919116647837856387556598', ),
                        extended_resources = runai.models.extended_resources_rules.ExtendedResourcesRules(
                            attributes = runai.models.extended_resource_rules.ExtendedResourceRules(
                                quantity = runai.models.string_rules.StringRules(), ), ),
                        gpu_devices_request = runai.models.integer_rules.IntegerRules(
                            required = True,
                            can_edit = True,
                            min = 56,
                            max = 56,
                            step = 56, ),
                        gpu_memory_limit = ,
                        gpu_memory_request = ,
                        gpu_portion_limit = ,
                        gpu_portion_request = ,
                        gpu_request_type = runai.models.gpu_request_rules.GpuRequestRules(),
                        large_shm_request = runai.models.boolean_rules.BooleanRules(
                            required = True,
                            can_edit = True, ), ),
                    create_home_dir = runai.models.boolean_rules.BooleanRules(
                        required = True,
                        can_edit = True, ),
                    environment_variables = runai.models.instances_rules.InstancesRules(),
                    image = runai.models.string_rules.StringRules(),
                    image_pull_policy = runai.models.image_pull_policy_rules.ImagePullPolicyRules(),
                    image_pull_secrets = runai.models.image_pull_secrets_rules.ImagePullSecretsRules(),
                    labels = ,
                    node_affinity_required = runai.models.arbitrary_rules.ArbitraryRules(
                        required = True,
                        can_edit = True, ),
                    node_type = runai.models.string_rules.StringRules(),
                    pod_affinity = runai.models.pod_affinity_rules.PodAffinityRules(
                        type = runai.models.pod_affinity_type_rules.PodAffinityTypeRules(),
                        key = runai.models.string_rules.StringRules(), ),
                    probes = runai.models.probes_rules.ProbesRules(
                        readiness = runai.models.probe_rules.ProbeRules(
                            initial_delay_seconds = runai.models.integer_rules.IntegerRules(
                                required = True,
                                can_edit = True,
                                min = 56,
                                max = 56,
                                step = 56, ),
                            period_seconds = ,
                            timeout_seconds = ,
                            success_threshold = ,
                            failure_threshold = ,
                            handler = runai.models.probe_handler_rules.ProbeHandlerRules(
                                http_get = runai.models.probe_handler_rules_http_get.ProbeHandlerRules_httpGet(
                                    path = runai.models.string_rules.StringRules(),
                                    port = ,
                                    host = runai.models.string_rules.StringRules(),
                                    scheme = runai.models.string_rules.StringRules(), ), ), ), ),
                    security = runai.models.inference_policy_rules_v2_all_of_security.InferencePolicyRulesV2_allOf_security(
                        capabilities = runai.models.array_rules.ArrayRules(
                            required = True,
                            options = [
                                {"value":"value","displayed":"A description of the value."}
                                ],
                            can_edit = True, ),
                        read_only_root_filesystem = ,
                        run_as_gid = runai.models.integer_rules_optional.IntegerRulesOptional(
                            can_edit = True,
                            min = 56,
                            max = 56,
                            step = 56, ),
                        run_as_non_root = ,
                        run_as_uid = runai.models.integer_rules_optional.IntegerRulesOptional(
                            can_edit = True,
                            min = 56,
                            max = 56,
                            step = 56, ),
                        seccomp_profile_type = runai.models.seccomp_profile_type_rules.SeccompProfileTypeRules(),
                        supplemental_groups = runai.models.string_rules.StringRules(),
                        uid_gid_source = runai.models.uid_gid_source_rules.UidGidSourceRules(), ),
                    storage = runai.models.distributed_inference_leader_worker_rules_v2_storage.DistributedInferenceLeaderWorkerRulesV2_storage(
                        config_map_volume = runai.models.config_maps_rules.ConfigMapsRules(),
                        empty_dir_volume = runai.models.empty_dirs_rules.EmptyDirsRules(),
                        pvc = runai.models.pvcs_rules.PvcsRules(),
                        secret_volume = runai.models.secrets_rules.SecretsRules(), ),
                    tolerations = runai.models.tolerations_rules.TolerationsRules(),
                    working_dir = runai.models.string_rules.StringRules(), )
        )
        ```
    """  # noqa: E501

    worker: Optional[DistributedInferenceLeaderWorkerRulesV2] = Field(
        default=None,
        description="Defines the pod specification for the workers. Required only if the number of workers is greater than 0.",
    )
    __properties: ClassVar[List[str]] = ["worker"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DistributedInferenceWorkerRules from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of worker
        if self.worker:
            _dict["worker"] = self.worker.to_dict()
        # set to None if worker (nullable) is None
        # and model_fields_set contains the field
        if self.worker is None and "worker" in self.model_fields_set:
            _dict["worker"] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DistributedInferenceWorkerRules from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "worker": (
                    DistributedInferenceLeaderWorkerRulesV2.from_dict(obj["worker"])
                    if obj.get("worker") is not None
                    else None
                )
            }
        )
        return _obj
