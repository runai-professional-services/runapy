# coding: utf-8

"""
NVIDIA Run:ai

# Introduction  The NVIDIA Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  NVIDIA Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create a **Service account** through the NVIDIA Run:ai user interface. To create a service account, in your UI, go to Access → Service Accounts (for organization-level service accounts) or User settings → Access Keys (for user access keys), and create a new one.  After you have created a new service account, you will need to assign it access rules. To assign access rules to the service account, see [Create access rules](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/accessrules#create-or-delete-rules). Make sure you assign the correct rules to your service account. Use the [Roles](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://run-ai-docs.nvidia.com/saas/reference/api/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from runai.models.distributed_inference_leader_worker_defaults_v2 import (
    DistributedInferenceLeaderWorkerDefaultsV2,
)
from runai.models.distributed_inference_restart_policy import (
    DistributedInferenceRestartPolicy,
)
from runai.models.distributed_inference_serving_port import (
    DistributedInferenceServingPort,
)
from runai.models.distributed_inference_startup_policy import (
    DistributedInferenceStartupPolicy,
)
from runai.models.preemptibility import Preemptibility
from typing import Optional, Set
from typing_extensions import Self


class DistributedInferenceDefaultsV2(BaseModel):
    """
    Pydantic class model representing DistributedInferenceDefaultsV2.

    Parameters:
        ```python
        category: Optional[str]
        node_pools: Optional[List[str]]
        preemptibility: Optional[Preemptibility]
        priority_class: Optional[str]
        restart_policy: Optional[DistributedInferenceRestartPolicy]
        serving_port: Optional[DistributedInferenceServingPort]
        startup_policy: Optional[DistributedInferenceStartupPolicy]
        workers: Optional[int]
        replicas: Optional[int]
        leader: Optional[DistributedInferenceLeaderWorkerDefaultsV2]
        worker: Optional[DistributedInferenceLeaderWorkerDefaultsV2]
        ```
        category: Specify the workload category assigned to the workload. Categories are used to classify and monitor different types of workloads within the NVIDIA Run:ai platform.
        node_pools: A prioritized list of node pools for the scheduler to run the workload on. The scheduler will always try to use the first node pool before moving to the next one if the first is not available.
        preemptibility: See model Preemptibility for more information.
        priority_class: Specifies the priority class for the workload, which determines its scheduling behavior. Valid values are: very-low, low, medium-low, medium, medium-high, high, and very-high. Each workload type has a default priority. To view the default priority for each workload type, use the GET /workload-types endpoint. Once you change the priority from the default value defined for that workload type, the preemptibility field is not automatically updated. Make sure to set the desired preemptibility value.
        restart_policy: See model DistributedInferenceRestartPolicy for more information. - Default: DistributedInferenceRestartPolicy.RECREATEGROUPONPODRESTART
        serving_port: See model DistributedInferenceServingPort for more information.
        startup_policy: See model DistributedInferenceStartupPolicy for more information. - Default: DistributedInferenceStartupPolicy.LEADERCREATED
        workers: Specifies the number of worker nodes to run. If set to 0, only the leader node will run, and no worker pods will be created. In this case, worker spec is not required. - Default: 0
        replicas: Specifies the number of leader-worker sets to deploy. Each replica represents a group consisting of one leader pod and multiple worker pods.  For example, setting replicas: 3 will create 3 independent groups, each with its own leader and corresponding set of workers.  - Default: 1
        leader: Defines the pod specification for the leader. Must always be provided, regardless of the number of workers.
        worker: Defines the pod specification for the workers. Required only if the number of workers is greater than 0.
    Example:
        ```python
        DistributedInferenceDefaultsV2(
            category='jUR,rZ#UM/?R,Fp^l6$ARj',
                        node_pools=["my-node-pool-a","my-node-pool-b"],
                        preemptibility='preemptible',
                        priority_class='jUR,rZ#UM/?R,Fp^l6$ARj',
                        restart_policy='RecreateGroupOnPodRestart',
                        serving_port=runai.models.distributed_inference_serving_port.DistributedInferenceServingPort(),
                        startup_policy='LeaderCreated',
                        workers=4,
                        replicas=2,
                        leader=runai.models.distributed_inference_leader_worker_defaults_v2.DistributedInferenceLeaderWorkerDefaultsV2(
                    annotations = runai.models.annotations_defaults.AnnotationsDefaults(
                        instances = [
                            runai.models.annotation.Annotation(
                                name = 'billing',
                                value = 'my-billing-unit',
                                exclude = False, )
                            ], ),
                    args = '-x my-script.py',
                    command = 'python',
                    compute = runai.models.superset_defaults_all_of_compute.SupersetDefaults_allOf_compute(
                        cpu_core_limit = 2,
                        cpu_core_request = 0.5,
                        cpu_memory_limit = '30M',
                        cpu_memory_request = '20M',
                        extended_resources = runai.models.extended_resources_defaults.ExtendedResourcesDefaults(
                            attributes = runai.models.extended_resource.ExtendedResource(
                                resource = 'hardware-vendor.example/foo',
                                quantity = '2',
                                exclude = False, ),
                            instances = [
                                runai.models.extended_resource.ExtendedResource(
                                    resource = 'hardware-vendor.example/foo',
                                    quantity = '2',
                                    exclude = False, )
                                ], ),
                        gpu_devices_request = 1,
                        gpu_memory_limit = '10M',
                        gpu_memory_request = '10M',
                        gpu_portion_limit = 0.5,
                        gpu_portion_request = 0.5,
                        gpu_request_type = 'portion',
                        large_shm_request = False, ),
                    create_home_dir = True,
                    environment_variables = runai.models.environment_variables_defaults.EnvironmentVariablesDefaults(
                        instances = [
                            runai.models.environment_variable.EnvironmentVariable(
                                name = 'HOME',
                                value = '/home/my-folder',
                                secret = runai.models.environment_variable_secret.EnvironmentVariableSecret(
                                    name = 'postgress_secret',
                                    key = 'POSTGRES_PASSWORD', ),
                                config_map = runai.models.environment_variable_config_map.EnvironmentVariableConfigMap(
                                    name = 'my-config-map',
                                    key = 'MY_POSTGRES_SCHEMA', ),
                                pod_field_ref = runai.models.environment_variable_pod_field_reference.EnvironmentVariablePodFieldReference(
                                    path = 'metadata.name', ),
                                user_credential = runai.models.environment_variable_user_credential.EnvironmentVariableUserCredential(
                                    name = 'my_postgres_user_and_password',
                                    key = 'POSTGRES_PASSWORD', ),
                                exclude = False,
                                description = 'Home directory of the user.', )
                            ], ),
                    image = 'python:3.8',
                    image_pull_policy = 'Always',
                    image_pull_secrets = runai.models.image_pull_secrets_defaults.ImagePullSecretsDefaults(
                        instances = [
                            runai.models.image_pull_secret.ImagePullSecret(
                                name = 'w1c2v7s6djuy1zmetozkhdomha1bae37b8ocvx8o53ow2eg7p6qw9qklp6l4y010fogx',
                                exclude = False, )
                            ], ),
                    labels = runai.models.labels_defaults.LabelsDefaults(
                        instances = [
                            runai.models.label.Label(
                                name = 'stage',
                                value = 'initial-research',
                                exclude = False, )
                            ], ),
                    node_affinity_required = runai.models.node_affinity_required.NodeAffinityRequired(
                        node_selector_terms = [
                            runai.models.node_selector_term.NodeSelectorTerm(
                                match_expressions = [
                                    runai.models.match_expression.MatchExpression(
                                        key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                                        operator = 'In',
                                        values = [
                                            'jUR,rZ#UM/?R,Fp^l6$ARj'
                                            ], )
                                    ], )
                            ], ),
                    node_type = 'my-node-type',
                    pod_affinity = runai.models.pod_affinity.PodAffinity(
                        type = 'Required',
                        key = 'jUR,rZ#UM/?R,Fp^l6$ARj', ),
                    probes = runai.models.probes.Probes(
                        readiness = runai.models.probe.Probe(
                            initial_delay_seconds = 0,
                            period_seconds = 1,
                            timeout_seconds = 1,
                            success_threshold = 1,
                            failure_threshold = 1,
                            handler = runai.models.probe_handler.ProbeHandler(
                                http_get = runai.models.probe_handler_http_get.ProbeHandler_httpGet(
                                    path = '/',
                                    port = 1,
                                    host = 'example.com',
                                    scheme = 'HTTP', ), ), ), ),
                    security = runai.models.inference_policy_defaults_v2_all_of_security.InferencePolicyDefaultsV2_allOf_security(
                        capabilities = ["CHOWN","KILL"],
                        read_only_root_filesystem = False,
                        run_as_gid = 30,
                        run_as_non_root = True,
                        run_as_uid = 500,
                        seccomp_profile_type = 'RuntimeDefault',
                        supplemental_groups = '2,3,5,8',
                        uid_gid_source = 'fromTheImage', ),
                    storage = runai.models.distributed_inference_leader_worker_defaults_v2_storage.DistributedInferenceLeaderWorkerDefaultsV2_storage(
                        config_map_volume = runai.models.config_maps_defaults.ConfigMapsDefaults(
                            instances = [
                                runai.models.config_map_instance.ConfigMapInstance()
                                ], ),
                        empty_dir_volume = runai.models.empty_dirs_defaults.EmptyDirsDefaults(
                            instances = [
                                runai.models.empty_dir_instance.EmptyDirInstance()
                                ], ),
                        pvc = runai.models.pvcs_defaults.PvcsDefaults(
                            instances = [
                                runai.models.pvc_instance.PvcInstance()
                                ], ),
                        secret_volume = runai.models.secrets_defaults.SecretsDefaults(
                            instances = [
                                runai.models.secret_instance2.SecretInstance2()
                                ], ), ),
                    tolerations = runai.models.tolerations_defaults.TolerationsDefaults(
                        instances = [
                            runai.models.toleration.Toleration(
                                name = 'jUR,rZ#UM/?R,Fp^l6$ARj0',
                                key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                                value = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                                effect = 'NoSchedule',
                                seconds = 1,
                                exclude = False, )
                            ], ),
                    working_dir = '/home/myfolder', ),
                        worker=runai.models.distributed_inference_leader_worker_defaults_v2.DistributedInferenceLeaderWorkerDefaultsV2(
                    annotations = runai.models.annotations_defaults.AnnotationsDefaults(
                        instances = [
                            runai.models.annotation.Annotation(
                                name = 'billing',
                                value = 'my-billing-unit',
                                exclude = False, )
                            ], ),
                    args = '-x my-script.py',
                    command = 'python',
                    compute = runai.models.superset_defaults_all_of_compute.SupersetDefaults_allOf_compute(
                        cpu_core_limit = 2,
                        cpu_core_request = 0.5,
                        cpu_memory_limit = '30M',
                        cpu_memory_request = '20M',
                        extended_resources = runai.models.extended_resources_defaults.ExtendedResourcesDefaults(
                            attributes = runai.models.extended_resource.ExtendedResource(
                                resource = 'hardware-vendor.example/foo',
                                quantity = '2',
                                exclude = False, ),
                            instances = [
                                runai.models.extended_resource.ExtendedResource(
                                    resource = 'hardware-vendor.example/foo',
                                    quantity = '2',
                                    exclude = False, )
                                ], ),
                        gpu_devices_request = 1,
                        gpu_memory_limit = '10M',
                        gpu_memory_request = '10M',
                        gpu_portion_limit = 0.5,
                        gpu_portion_request = 0.5,
                        gpu_request_type = 'portion',
                        large_shm_request = False, ),
                    create_home_dir = True,
                    environment_variables = runai.models.environment_variables_defaults.EnvironmentVariablesDefaults(
                        instances = [
                            runai.models.environment_variable.EnvironmentVariable(
                                name = 'HOME',
                                value = '/home/my-folder',
                                secret = runai.models.environment_variable_secret.EnvironmentVariableSecret(
                                    name = 'postgress_secret',
                                    key = 'POSTGRES_PASSWORD', ),
                                config_map = runai.models.environment_variable_config_map.EnvironmentVariableConfigMap(
                                    name = 'my-config-map',
                                    key = 'MY_POSTGRES_SCHEMA', ),
                                pod_field_ref = runai.models.environment_variable_pod_field_reference.EnvironmentVariablePodFieldReference(
                                    path = 'metadata.name', ),
                                user_credential = runai.models.environment_variable_user_credential.EnvironmentVariableUserCredential(
                                    name = 'my_postgres_user_and_password',
                                    key = 'POSTGRES_PASSWORD', ),
                                exclude = False,
                                description = 'Home directory of the user.', )
                            ], ),
                    image = 'python:3.8',
                    image_pull_policy = 'Always',
                    image_pull_secrets = runai.models.image_pull_secrets_defaults.ImagePullSecretsDefaults(
                        instances = [
                            runai.models.image_pull_secret.ImagePullSecret(
                                name = 'w1c2v7s6djuy1zmetozkhdomha1bae37b8ocvx8o53ow2eg7p6qw9qklp6l4y010fogx',
                                exclude = False, )
                            ], ),
                    labels = runai.models.labels_defaults.LabelsDefaults(
                        instances = [
                            runai.models.label.Label(
                                name = 'stage',
                                value = 'initial-research',
                                exclude = False, )
                            ], ),
                    node_affinity_required = runai.models.node_affinity_required.NodeAffinityRequired(
                        node_selector_terms = [
                            runai.models.node_selector_term.NodeSelectorTerm(
                                match_expressions = [
                                    runai.models.match_expression.MatchExpression(
                                        key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                                        operator = 'In',
                                        values = [
                                            'jUR,rZ#UM/?R,Fp^l6$ARj'
                                            ], )
                                    ], )
                            ], ),
                    node_type = 'my-node-type',
                    pod_affinity = runai.models.pod_affinity.PodAffinity(
                        type = 'Required',
                        key = 'jUR,rZ#UM/?R,Fp^l6$ARj', ),
                    probes = runai.models.probes.Probes(
                        readiness = runai.models.probe.Probe(
                            initial_delay_seconds = 0,
                            period_seconds = 1,
                            timeout_seconds = 1,
                            success_threshold = 1,
                            failure_threshold = 1,
                            handler = runai.models.probe_handler.ProbeHandler(
                                http_get = runai.models.probe_handler_http_get.ProbeHandler_httpGet(
                                    path = '/',
                                    port = 1,
                                    host = 'example.com',
                                    scheme = 'HTTP', ), ), ), ),
                    security = runai.models.inference_policy_defaults_v2_all_of_security.InferencePolicyDefaultsV2_allOf_security(
                        capabilities = ["CHOWN","KILL"],
                        read_only_root_filesystem = False,
                        run_as_gid = 30,
                        run_as_non_root = True,
                        run_as_uid = 500,
                        seccomp_profile_type = 'RuntimeDefault',
                        supplemental_groups = '2,3,5,8',
                        uid_gid_source = 'fromTheImage', ),
                    storage = runai.models.distributed_inference_leader_worker_defaults_v2_storage.DistributedInferenceLeaderWorkerDefaultsV2_storage(
                        config_map_volume = runai.models.config_maps_defaults.ConfigMapsDefaults(
                            instances = [
                                runai.models.config_map_instance.ConfigMapInstance()
                                ], ),
                        empty_dir_volume = runai.models.empty_dirs_defaults.EmptyDirsDefaults(
                            instances = [
                                runai.models.empty_dir_instance.EmptyDirInstance()
                                ], ),
                        pvc = runai.models.pvcs_defaults.PvcsDefaults(
                            instances = [
                                runai.models.pvc_instance.PvcInstance()
                                ], ),
                        secret_volume = runai.models.secrets_defaults.SecretsDefaults(
                            instances = [
                                runai.models.secret_instance2.SecretInstance2()
                                ], ), ),
                    tolerations = runai.models.tolerations_defaults.TolerationsDefaults(
                        instances = [
                            runai.models.toleration.Toleration(
                                name = 'jUR,rZ#UM/?R,Fp^l6$ARj0',
                                key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                                value = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                                effect = 'NoSchedule',
                                seconds = 1,
                                exclude = False, )
                            ], ),
                    working_dir = '/home/myfolder', )
        )
        ```
    """  # noqa: E501

    category: Optional[Annotated[str, Field(strict=True)]] = Field(
        default=None,
        description="Specify the workload category assigned to the workload. Categories are used to classify and monitor different types of workloads within the NVIDIA Run:ai platform.",
    )
    node_pools: Optional[List[Annotated[str, Field(strict=True)]]] = Field(
        default=None,
        description="A prioritized list of node pools for the scheduler to run the workload on. The scheduler will always try to use the first node pool before moving to the next one if the first is not available.",
        alias="nodePools",
    )
    preemptibility: Optional[Preemptibility] = None
    priority_class: Optional[Annotated[str, Field(strict=True)]] = Field(
        default=None,
        description="Specifies the priority class for the workload, which determines its scheduling behavior. Valid values are: very-low, low, medium-low, medium, medium-high, high, and very-high. Each workload type has a default priority. To view the default priority for each workload type, use the GET /workload-types endpoint. Once you change the priority from the default value defined for that workload type, the preemptibility field is not automatically updated. Make sure to set the desired preemptibility value.",
        alias="priorityClass",
    )
    restart_policy: Optional[DistributedInferenceRestartPolicy] = Field(
        default=DistributedInferenceRestartPolicy.RECREATEGROUPONPODRESTART,
        alias="restartPolicy",
    )
    serving_port: Optional[DistributedInferenceServingPort] = Field(
        default=None, alias="servingPort"
    )
    startup_policy: Optional[DistributedInferenceStartupPolicy] = Field(
        default=DistributedInferenceStartupPolicy.LEADERCREATED, alias="startupPolicy"
    )
    workers: Optional[Annotated[int, Field(le=1000, strict=True, ge=0)]] = Field(
        default=0,
        description="Specifies the number of worker nodes to run. If set to 0, only the leader node will run, and no worker pods will be created. In this case, worker spec is not required.",
    )
    replicas: Optional[Annotated[int, Field(le=1000, strict=True, ge=0)]] = Field(
        default=1,
        description="Specifies the number of leader-worker sets to deploy. Each replica represents a group consisting of one leader pod and multiple worker pods.  For example, setting replicas: 3 will create 3 independent groups, each with its own leader and corresponding set of workers. ",
    )
    leader: Optional[DistributedInferenceLeaderWorkerDefaultsV2] = Field(
        default=None,
        description="Defines the pod specification for the leader. Must always be provided, regardless of the number of workers.",
    )
    worker: Optional[DistributedInferenceLeaderWorkerDefaultsV2] = Field(
        default=None,
        description="Defines the pod specification for the workers. Required only if the number of workers is greater than 0.",
    )
    __properties: ClassVar[List[str]] = [
        "category",
        "nodePools",
        "preemptibility",
        "priorityClass",
        "restartPolicy",
        "servingPort",
        "startupPolicy",
        "workers",
        "replicas",
        "leader",
        "worker",
    ]

    @field_validator("category")
    def category_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("priority_class")
    def priority_class_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DistributedInferenceDefaultsV2 from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of serving_port
        if self.serving_port:
            _dict["servingPort"] = self.serving_port.to_dict()
        # override the default output from pydantic by calling `to_dict()` of leader
        if self.leader:
            _dict["leader"] = self.leader.to_dict()
        # override the default output from pydantic by calling `to_dict()` of worker
        if self.worker:
            _dict["worker"] = self.worker.to_dict()
        # set to None if category (nullable) is None
        # and model_fields_set contains the field
        if self.category is None and "category" in self.model_fields_set:
            _dict["category"] = None

        # set to None if node_pools (nullable) is None
        # and model_fields_set contains the field
        if self.node_pools is None and "node_pools" in self.model_fields_set:
            _dict["nodePools"] = None

        # set to None if preemptibility (nullable) is None
        # and model_fields_set contains the field
        if self.preemptibility is None and "preemptibility" in self.model_fields_set:
            _dict["preemptibility"] = None

        # set to None if priority_class (nullable) is None
        # and model_fields_set contains the field
        if self.priority_class is None and "priority_class" in self.model_fields_set:
            _dict["priorityClass"] = None

        # set to None if restart_policy (nullable) is None
        # and model_fields_set contains the field
        if self.restart_policy is None and "restart_policy" in self.model_fields_set:
            _dict["restartPolicy"] = None

        # set to None if serving_port (nullable) is None
        # and model_fields_set contains the field
        if self.serving_port is None and "serving_port" in self.model_fields_set:
            _dict["servingPort"] = None

        # set to None if startup_policy (nullable) is None
        # and model_fields_set contains the field
        if self.startup_policy is None and "startup_policy" in self.model_fields_set:
            _dict["startupPolicy"] = None

        # set to None if workers (nullable) is None
        # and model_fields_set contains the field
        if self.workers is None and "workers" in self.model_fields_set:
            _dict["workers"] = None

        # set to None if replicas (nullable) is None
        # and model_fields_set contains the field
        if self.replicas is None and "replicas" in self.model_fields_set:
            _dict["replicas"] = None

        # set to None if leader (nullable) is None
        # and model_fields_set contains the field
        if self.leader is None and "leader" in self.model_fields_set:
            _dict["leader"] = None

        # set to None if worker (nullable) is None
        # and model_fields_set contains the field
        if self.worker is None and "worker" in self.model_fields_set:
            _dict["worker"] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DistributedInferenceDefaultsV2 from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "category": obj.get("category"),
                "nodePools": obj.get("nodePools"),
                "preemptibility": obj.get("preemptibility"),
                "priorityClass": obj.get("priorityClass"),
                "restartPolicy": (
                    obj.get("restartPolicy")
                    if obj.get("restartPolicy") is not None
                    else DistributedInferenceRestartPolicy.RECREATEGROUPONPODRESTART
                ),
                "servingPort": (
                    DistributedInferenceServingPort.from_dict(obj["servingPort"])
                    if obj.get("servingPort") is not None
                    else None
                ),
                "startupPolicy": (
                    obj.get("startupPolicy")
                    if obj.get("startupPolicy") is not None
                    else DistributedInferenceStartupPolicy.LEADERCREATED
                ),
                "workers": obj.get("workers") if obj.get("workers") is not None else 0,
                "replicas": (
                    obj.get("replicas") if obj.get("replicas") is not None else 1
                ),
                "leader": (
                    DistributedInferenceLeaderWorkerDefaultsV2.from_dict(obj["leader"])
                    if obj.get("leader") is not None
                    else None
                ),
                "worker": (
                    DistributedInferenceLeaderWorkerDefaultsV2.from_dict(obj["worker"])
                    if obj.get("worker") is not None
                    else None
                ),
            }
        )
        return _obj
