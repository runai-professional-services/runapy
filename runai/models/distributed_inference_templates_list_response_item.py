# coding: utf-8

"""
NVIDIA Run:ai

# Introduction  The NVIDIA Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  NVIDIA Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create a **Service account** through the NVIDIA Run:ai user interface. To create a service account, in your UI, go to Access → Service Accounts (for organization-level service accounts) or User settings → Access Keys (for user access keys), and create a new one.  After you have created a new service account, you will need to assign it access rules. To assign access rules to the service account, see [Create access rules](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/accessrules#create-or-delete-rules). Make sure you assign the correct rules to your service account. Use the [Roles](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://run-ai-docs.nvidia.com/saas/reference/api/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field
from typing import Any, ClassVar, Dict, List, Optional
from runai.models.compliance_info_reason import ComplianceInfoReason
from runai.models.distributed_inference_template_spec import (
    DistributedInferenceTemplateSpec,
)
from runai.models.runnable_info import RunnableInfo
from runai.models.template_meta_fields import TemplateMetaFields
from typing import Optional, Set
from typing_extensions import Self


class DistributedInferenceTemplatesListResponseItem(BaseModel):
    """
    Pydantic class model representing DistributedInferenceTemplatesListResponseItem.

    Parameters:
        ```python
        meta: TemplateMetaFields
        spec: DistributedInferenceTemplateSpec
        runnable: RunnableInfo
        combined_spec: DistributedInferenceTemplateSpec
        compliance_issues: List[ComplianceInfoReason]
        ```
        meta: See model TemplateMetaFields for more information.
        spec: See model DistributedInferenceTemplateSpec for more information.
        runnable: See model RunnableInfo for more information.
        combined_spec: See model DistributedInferenceTemplateSpec for more information.
        compliance_issues: A list of issues preventing the use of a template or asset for creating workloads in a given project.
    Example:
        ```python
        DistributedInferenceTemplatesListResponseItem(
            meta=runai.models.template_meta_fields.TemplateMetaFields(
                    id = '550e8400-e29b-41d4-a716-446655440000',
                    name = 'my-template-name',
                    description = 'description of my template.',
                    workload_type = 'Workspace',
                    scope_type = 'system',
                    scope_id = '',
                    cluster_id = '71f69d83-ba66-4822-adf5-55ce55efd210',
                    department_id = '2',
                    project_id = 1,
                    created_by = 'test@lab.com',
                    created_at = '2022-01-01T03:49:52.531Z',
                    updated_by = 'test@lab.com',
                    updated_at = '2022-01-01T03:49:52.531Z', ),
                        spec="example",
                        runnable=runai.models.runnable_info.RunnableInfo(
                    is_runnable = False,
                    issue = 'mandatory image is not provided', ),
                        combined_spec="example",
                        compliance_issues=[
                    runai.models.compliance_info_reason.ComplianceInfoReason(
                        field = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                        details = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                        rule = 'min', )
                    ]
        )
        ```
    """  # noqa: E501

    meta: TemplateMetaFields
    spec: Optional[DistributedInferenceTemplateSpec] = None
    runnable: Optional[RunnableInfo] = None
    combined_spec: Optional[DistributedInferenceTemplateSpec] = Field(
        default=None, alias="combinedSpec"
    )
    compliance_issues: Optional[List[ComplianceInfoReason]] = Field(
        default=None,
        description="A list of issues preventing the use of a template or asset for creating workloads in a given project.",
        alias="complianceIssues",
    )
    __properties: ClassVar[List[str]] = [
        "meta",
        "spec",
        "runnable",
        "combinedSpec",
        "complianceIssues",
    ]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DistributedInferenceTemplatesListResponseItem from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of meta
        if self.meta:
            _dict["meta"] = self.meta.to_dict()
        # override the default output from pydantic by calling `to_dict()` of spec
        if self.spec:
            _dict["spec"] = self.spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of runnable
        if self.runnable:
            _dict["runnable"] = self.runnable.to_dict()
        # override the default output from pydantic by calling `to_dict()` of combined_spec
        if self.combined_spec:
            _dict["combinedSpec"] = self.combined_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in compliance_issues (list)
        _items = []
        if self.compliance_issues:
            for _item_compliance_issues in self.compliance_issues:
                if _item_compliance_issues:
                    _items.append(_item_compliance_issues.to_dict())
            _dict["complianceIssues"] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DistributedInferenceTemplatesListResponseItem from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "meta": (
                    TemplateMetaFields.from_dict(obj["meta"])
                    if obj.get("meta") is not None
                    else None
                ),
                "spec": (
                    DistributedInferenceTemplateSpec.from_dict(obj["spec"])
                    if obj.get("spec") is not None
                    else None
                ),
                "runnable": (
                    RunnableInfo.from_dict(obj["runnable"])
                    if obj.get("runnable") is not None
                    else None
                ),
                "combinedSpec": (
                    DistributedInferenceTemplateSpec.from_dict(obj["combinedSpec"])
                    if obj.get("combinedSpec") is not None
                    else None
                ),
                "complianceIssues": (
                    [
                        ComplianceInfoReason.from_dict(_item)
                        for _item in obj["complianceIssues"]
                    ]
                    if obj.get("complianceIssues") is not None
                    else None
                ),
            }
        )
        return _obj
