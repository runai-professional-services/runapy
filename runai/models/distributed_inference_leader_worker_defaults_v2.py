# coding: utf-8

"""
NVIDIA Run:ai

# Introduction  The NVIDIA Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  NVIDIA Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create a **Service account** through the NVIDIA Run:ai user interface. To create a service account, in your UI, go to Access → Service Accounts (for organization-level service accounts) or User settings → Access Keys (for user access keys), and create a new one.  After you have created a new service account, you will need to assign it access rules. To assign access rules to the service account, see [Create access rules](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/accessrules#create-or-delete-rules). Make sure you assign the correct rules to your service account. Use the [Roles](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://run-ai-docs.nvidia.com/saas/reference/api/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from runai.models.annotations_defaults import AnnotationsDefaults
from runai.models.distributed_inference_leader_worker_defaults_v2_storage import (
    DistributedInferenceLeaderWorkerDefaultsV2Storage,
)
from runai.models.environment_variables_defaults import EnvironmentVariablesDefaults
from runai.models.image_pull_policy import ImagePullPolicy
from runai.models.image_pull_secrets_defaults import ImagePullSecretsDefaults
from runai.models.inference_policy_defaults_v2_all_of_security import (
    InferencePolicyDefaultsV2AllOfSecurity,
)
from runai.models.labels_defaults import LabelsDefaults
from runai.models.node_affinity_required import NodeAffinityRequired
from runai.models.pod_affinity import PodAffinity
from runai.models.probes import Probes
from runai.models.superset_defaults_all_of_compute import SupersetDefaultsAllOfCompute
from runai.models.tolerations_defaults import TolerationsDefaults
from typing import Optional, Set
from typing_extensions import Self


class DistributedInferenceLeaderWorkerDefaultsV2(BaseModel):
    """
    Pydantic class model representing DistributedInferenceLeaderWorkerDefaultsV2.

    Parameters:
        ```python
        annotations: Optional[AnnotationsDefaults]
        args: Optional[str]
        command: Optional[str]
        compute: Optional[SupersetDefaultsAllOfCompute]
        create_home_dir: Optional[bool]
        environment_variables: Optional[EnvironmentVariablesDefaults]
        image: Optional[str]
        image_pull_policy: Optional[ImagePullPolicy]
        image_pull_secrets: Optional[ImagePullSecretsDefaults]
        labels: Optional[LabelsDefaults]
        node_affinity_required: Optional[NodeAffinityRequired]
        node_type: Optional[str]
        pod_affinity: Optional[PodAffinity]
        probes: Optional[Probes]
        security: Optional[InferencePolicyDefaultsV2AllOfSecurity]
        storage: Optional[DistributedInferenceLeaderWorkerDefaultsV2Storage]
        tolerations: Optional[TolerationsDefaults]
        working_dir: Optional[str]
        ```
        annotations: See model AnnotationsDefaults for more information.
        args: Arguments to the command that the container running the workload executes.
        command: A command to the server as the entry point of the container running the workload.
        compute: See model SupersetDefaultsAllOfCompute for more information.
        create_home_dir: When set to &#x60;true&#x60;, creates a home directory for the container.
        environment_variables: See model EnvironmentVariablesDefaults for more information.
        image: Docker image name. For more information, see [Images](https://kubernetes.io/docs/concepts/containers/images). The image name is mandatory for creating a workload.
        image_pull_policy: See model ImagePullPolicy for more information.
        image_pull_secrets: See model ImagePullSecretsDefaults for more information.
        labels: See model LabelsDefaults for more information.
        node_affinity_required: See model NodeAffinityRequired for more information.
        node_type: Nodes (machines), or a group of nodes on which the workload will run. To use this feature, your Administrator will need to label nodes. For more information, see [Group Nodes](https://docs.run.ai/latest/admin/researcher-setup/limit-to-node-group). When using this flag with with Project-based affinity, it refines the list of allowable node groups set in the Project. For more information, see [Projects](https://docshub.run.ai/guides/platform-management/aiinitiatives/organization/projects).
        pod_affinity: See model PodAffinity for more information.
        probes: See model Probes for more information.
        security: See model InferencePolicyDefaultsV2AllOfSecurity for more information.
        storage: See model DistributedInferenceLeaderWorkerDefaultsV2Storage for more information.
        tolerations: See model TolerationsDefaults for more information.
        working_dir: Container&#39;s working directory. If not specified, the container runtime default will be used. This may be configured in the container image.
    Example:
        ```python
        DistributedInferenceLeaderWorkerDefaultsV2(
            annotations=runai.models.annotations_defaults.AnnotationsDefaults(
                    instances = [
                        runai.models.annotation.Annotation(
                            name = 'billing',
                            value = 'my-billing-unit',
                            exclude = False, )
                        ], ),
                        args='-x my-script.py',
                        command='python',
                        compute=runai.models.superset_defaults_all_of_compute.SupersetDefaults_allOf_compute(
                    cpu_core_limit = 2,
                    cpu_core_request = 0.5,
                    cpu_memory_limit = '30M',
                    cpu_memory_request = '20M',
                    extended_resources = runai.models.extended_resources_defaults.ExtendedResourcesDefaults(
                        attributes = runai.models.extended_resource.ExtendedResource(
                            resource = 'hardware-vendor.example/foo',
                            quantity = '2',
                            exclude = False, ),
                        instances = [
                            runai.models.extended_resource.ExtendedResource(
                                resource = 'hardware-vendor.example/foo',
                                quantity = '2',
                                exclude = False, )
                            ], ),
                    gpu_devices_request = 1,
                    gpu_memory_limit = '10M',
                    gpu_memory_request = '10M',
                    gpu_portion_limit = 0.5,
                    gpu_portion_request = 0.5,
                    gpu_request_type = 'portion',
                    large_shm_request = False, ),
                        create_home_dir=True,
                        environment_variables=runai.models.environment_variables_defaults.EnvironmentVariablesDefaults(
                    instances = [
                        runai.models.environment_variable.EnvironmentVariable(
                            name = 'HOME',
                            value = '/home/my-folder',
                            secret = runai.models.environment_variable_secret.EnvironmentVariableSecret(
                                name = 'postgress_secret',
                                key = 'POSTGRES_PASSWORD', ),
                            config_map = runai.models.environment_variable_config_map.EnvironmentVariableConfigMap(
                                name = 'my-config-map',
                                key = 'MY_POSTGRES_SCHEMA', ),
                            pod_field_ref = runai.models.environment_variable_pod_field_reference.EnvironmentVariablePodFieldReference(
                                path = 'metadata.name', ),
                            user_credential = runai.models.environment_variable_user_credential.EnvironmentVariableUserCredential(
                                name = 'my_postgres_user_and_password',
                                key = 'POSTGRES_PASSWORD', ),
                            exclude = False,
                            description = 'Home directory of the user.', )
                        ], ),
                        image='python:3.8',
                        image_pull_policy='Always',
                        image_pull_secrets=runai.models.image_pull_secrets_defaults.ImagePullSecretsDefaults(
                    instances = [
                        runai.models.image_pull_secret.ImagePullSecret(
                            name = 'w1c2v7s6djuy1zmetozkhdomha1bae37b8ocvx8o53ow2eg7p6qw9qklp6l4y010fogx',
                            user_credential = True,
                            exclude = False, )
                        ], ),
                        labels=runai.models.labels_defaults.LabelsDefaults(
                    instances = [
                        runai.models.label.Label(
                            name = 'stage',
                            value = 'initial-research',
                            exclude = False, )
                        ], ),
                        node_affinity_required=runai.models.node_affinity_required.NodeAffinityRequired(
                    node_selector_terms = [
                        runai.models.node_selector_term.NodeSelectorTerm(
                            match_expressions = [
                                runai.models.match_expression.MatchExpression(
                                    key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                                    operator = 'In',
                                    values = [
                                        'jUR,rZ#UM/?R,Fp^l6$ARj'
                                        ], )
                                ], )
                        ], ),
                        node_type='my-node-type',
                        pod_affinity=runai.models.pod_affinity.PodAffinity(
                    type = 'Required',
                    key = 'jUR,rZ#UM/?R,Fp^l6$ARj', ),
                        probes=runai.models.probes.Probes(
                    readiness = runai.models.probe.Probe(
                        initial_delay_seconds = 0,
                        period_seconds = 1,
                        timeout_seconds = 1,
                        success_threshold = 1,
                        failure_threshold = 1,
                        handler = runai.models.probe_handler.ProbeHandler(
                            http_get = runai.models.probe_handler_http_get.ProbeHandler_httpGet(
                                path = '/',
                                port = 1,
                                host = 'example.com',
                                scheme = 'HTTP', ), ), ), ),
                        security=runai.models.inference_policy_defaults_v2_all_of_security.InferencePolicyDefaultsV2_allOf_security(
                    capabilities = ["CHOWN","KILL"],
                    read_only_root_filesystem = False,
                    run_as_gid = 30,
                    run_as_non_root = True,
                    run_as_uid = 500,
                    seccomp_profile_type = 'RuntimeDefault',
                    supplemental_groups = '2,3,5,8',
                    uid_gid_source = 'fromTheImage', ),
                        storage=runai.models.distributed_inference_leader_worker_defaults_v2_storage.DistributedInferenceLeaderWorkerDefaultsV2_storage(
                    config_map_volume = runai.models.config_maps_defaults.ConfigMapsDefaults(
                        attributes = runai.models.config_map_instance.ConfigMapInstance(),
                        instances = [
                            runai.models.config_map_instance.ConfigMapInstance()
                            ], ),
                    empty_dir_volume = runai.models.empty_dirs_defaults.EmptyDirsDefaults(
                        instances = [
                            runai.models.empty_dir_instance.EmptyDirInstance()
                            ], ),
                    pvc = runai.models.pvcs_defaults.PvcsDefaults(
                        instances = [
                            runai.models.pvc_instance.PvcInstance()
                            ], ),
                    secret_volume = runai.models.secrets_defaults.SecretsDefaults(
                        instances = [
                            runai.models.secret_instance2.SecretInstance2()
                            ], ), ),
                        tolerations=runai.models.tolerations_defaults.TolerationsDefaults(
                    attributes = runai.models.toleration.Toleration(
                        name = 'jUR,rZ#UM/?R,Fp^l6$ARj0',
                        operator = 'Equal',
                        key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                        value = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                        effect = 'NoSchedule',
                        seconds = 1,
                        exclude = False, ),
                    instances = [
                        runai.models.toleration.Toleration(
                            name = 'jUR,rZ#UM/?R,Fp^l6$ARj0',
                            key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                            value = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                            seconds = 1,
                            exclude = False, )
                        ], ),
                        working_dir='/home/myfolder'
        )
        ```
    """  # noqa: E501

    annotations: Optional[AnnotationsDefaults] = None
    args: Optional[Annotated[str, Field(min_length=1, strict=True)]] = Field(
        default=None,
        description="Arguments to the command that the container running the workload executes.",
    )
    command: Optional[Annotated[str, Field(min_length=1, strict=True)]] = Field(
        default=None,
        description="A command to the server as the entry point of the container running the workload.",
    )
    compute: Optional[SupersetDefaultsAllOfCompute] = None
    create_home_dir: Optional[StrictBool] = Field(
        default=None,
        description="When set to `true`, creates a home directory for the container.",
        alias="createHomeDir",
    )
    environment_variables: Optional[EnvironmentVariablesDefaults] = Field(
        default=None, alias="environmentVariables"
    )
    image: Optional[Annotated[str, Field(min_length=1, strict=True)]] = Field(
        default=None,
        description="Docker image name. For more information, see [Images](https://kubernetes.io/docs/concepts/containers/images). The image name is mandatory for creating a workload.",
    )
    image_pull_policy: Optional[ImagePullPolicy] = Field(
        default=None, alias="imagePullPolicy"
    )
    image_pull_secrets: Optional[ImagePullSecretsDefaults] = Field(
        default=None, alias="imagePullSecrets"
    )
    labels: Optional[LabelsDefaults] = None
    node_affinity_required: Optional[NodeAffinityRequired] = Field(
        default=None, alias="nodeAffinityRequired"
    )
    node_type: Optional[Annotated[str, Field(min_length=1, strict=True)]] = Field(
        default=None,
        description="Nodes (machines), or a group of nodes on which the workload will run. To use this feature, your Administrator will need to label nodes. For more information, see [Group Nodes](https://docs.run.ai/latest/admin/researcher-setup/limit-to-node-group). When using this flag with with Project-based affinity, it refines the list of allowable node groups set in the Project. For more information, see [Projects](https://docshub.run.ai/guides/platform-management/aiinitiatives/organization/projects).",
        alias="nodeType",
    )
    pod_affinity: Optional[PodAffinity] = Field(default=None, alias="podAffinity")
    probes: Optional[Probes] = None
    security: Optional[InferencePolicyDefaultsV2AllOfSecurity] = None
    storage: Optional[DistributedInferenceLeaderWorkerDefaultsV2Storage] = None
    tolerations: Optional[TolerationsDefaults] = None
    working_dir: Optional[Annotated[str, Field(min_length=1, strict=True)]] = Field(
        default=None,
        description="Container's working directory. If not specified, the container runtime default will be used. This may be configured in the container image.",
        alias="workingDir",
    )
    __properties: ClassVar[List[str]] = [
        "annotations",
        "args",
        "command",
        "compute",
        "createHomeDir",
        "environmentVariables",
        "image",
        "imagePullPolicy",
        "imagePullSecrets",
        "labels",
        "nodeAffinityRequired",
        "nodeType",
        "podAffinity",
        "probes",
        "security",
        "storage",
        "tolerations",
        "workingDir",
    ]

    @field_validator("args")
    def args_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("command")
    def command_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("image")
    def image_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("node_type")
    def node_type_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("working_dir")
    def working_dir_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DistributedInferenceLeaderWorkerDefaultsV2 from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of annotations
        if self.annotations:
            _dict["annotations"] = self.annotations.to_dict()
        # override the default output from pydantic by calling `to_dict()` of compute
        if self.compute:
            _dict["compute"] = self.compute.to_dict()
        # override the default output from pydantic by calling `to_dict()` of environment_variables
        if self.environment_variables:
            _dict["environmentVariables"] = self.environment_variables.to_dict()
        # override the default output from pydantic by calling `to_dict()` of image_pull_secrets
        if self.image_pull_secrets:
            _dict["imagePullSecrets"] = self.image_pull_secrets.to_dict()
        # override the default output from pydantic by calling `to_dict()` of labels
        if self.labels:
            _dict["labels"] = self.labels.to_dict()
        # override the default output from pydantic by calling `to_dict()` of node_affinity_required
        if self.node_affinity_required:
            _dict["nodeAffinityRequired"] = self.node_affinity_required.to_dict()
        # override the default output from pydantic by calling `to_dict()` of pod_affinity
        if self.pod_affinity:
            _dict["podAffinity"] = self.pod_affinity.to_dict()
        # override the default output from pydantic by calling `to_dict()` of probes
        if self.probes:
            _dict["probes"] = self.probes.to_dict()
        # override the default output from pydantic by calling `to_dict()` of security
        if self.security:
            _dict["security"] = self.security.to_dict()
        # override the default output from pydantic by calling `to_dict()` of storage
        if self.storage:
            _dict["storage"] = self.storage.to_dict()
        # override the default output from pydantic by calling `to_dict()` of tolerations
        if self.tolerations:
            _dict["tolerations"] = self.tolerations.to_dict()
        # set to None if annotations (nullable) is None
        # and model_fields_set contains the field
        if self.annotations is None and "annotations" in self.model_fields_set:
            _dict["annotations"] = None

        # set to None if args (nullable) is None
        # and model_fields_set contains the field
        if self.args is None and "args" in self.model_fields_set:
            _dict["args"] = None

        # set to None if command (nullable) is None
        # and model_fields_set contains the field
        if self.command is None and "command" in self.model_fields_set:
            _dict["command"] = None

        # set to None if compute (nullable) is None
        # and model_fields_set contains the field
        if self.compute is None and "compute" in self.model_fields_set:
            _dict["compute"] = None

        # set to None if create_home_dir (nullable) is None
        # and model_fields_set contains the field
        if self.create_home_dir is None and "create_home_dir" in self.model_fields_set:
            _dict["createHomeDir"] = None

        # set to None if environment_variables (nullable) is None
        # and model_fields_set contains the field
        if (
            self.environment_variables is None
            and "environment_variables" in self.model_fields_set
        ):
            _dict["environmentVariables"] = None

        # set to None if image (nullable) is None
        # and model_fields_set contains the field
        if self.image is None and "image" in self.model_fields_set:
            _dict["image"] = None

        # set to None if image_pull_policy (nullable) is None
        # and model_fields_set contains the field
        if (
            self.image_pull_policy is None
            and "image_pull_policy" in self.model_fields_set
        ):
            _dict["imagePullPolicy"] = None

        # set to None if image_pull_secrets (nullable) is None
        # and model_fields_set contains the field
        if (
            self.image_pull_secrets is None
            and "image_pull_secrets" in self.model_fields_set
        ):
            _dict["imagePullSecrets"] = None

        # set to None if labels (nullable) is None
        # and model_fields_set contains the field
        if self.labels is None and "labels" in self.model_fields_set:
            _dict["labels"] = None

        # set to None if node_affinity_required (nullable) is None
        # and model_fields_set contains the field
        if (
            self.node_affinity_required is None
            and "node_affinity_required" in self.model_fields_set
        ):
            _dict["nodeAffinityRequired"] = None

        # set to None if node_type (nullable) is None
        # and model_fields_set contains the field
        if self.node_type is None and "node_type" in self.model_fields_set:
            _dict["nodeType"] = None

        # set to None if pod_affinity (nullable) is None
        # and model_fields_set contains the field
        if self.pod_affinity is None and "pod_affinity" in self.model_fields_set:
            _dict["podAffinity"] = None

        # set to None if probes (nullable) is None
        # and model_fields_set contains the field
        if self.probes is None and "probes" in self.model_fields_set:
            _dict["probes"] = None

        # set to None if security (nullable) is None
        # and model_fields_set contains the field
        if self.security is None and "security" in self.model_fields_set:
            _dict["security"] = None

        # set to None if storage (nullable) is None
        # and model_fields_set contains the field
        if self.storage is None and "storage" in self.model_fields_set:
            _dict["storage"] = None

        # set to None if tolerations (nullable) is None
        # and model_fields_set contains the field
        if self.tolerations is None and "tolerations" in self.model_fields_set:
            _dict["tolerations"] = None

        # set to None if working_dir (nullable) is None
        # and model_fields_set contains the field
        if self.working_dir is None and "working_dir" in self.model_fields_set:
            _dict["workingDir"] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DistributedInferenceLeaderWorkerDefaultsV2 from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "annotations": (
                    AnnotationsDefaults.from_dict(obj["annotations"])
                    if obj.get("annotations") is not None
                    else None
                ),
                "args": obj.get("args"),
                "command": obj.get("command"),
                "compute": (
                    SupersetDefaultsAllOfCompute.from_dict(obj["compute"])
                    if obj.get("compute") is not None
                    else None
                ),
                "createHomeDir": obj.get("createHomeDir"),
                "environmentVariables": (
                    EnvironmentVariablesDefaults.from_dict(obj["environmentVariables"])
                    if obj.get("environmentVariables") is not None
                    else None
                ),
                "image": obj.get("image"),
                "imagePullPolicy": obj.get("imagePullPolicy"),
                "imagePullSecrets": (
                    ImagePullSecretsDefaults.from_dict(obj["imagePullSecrets"])
                    if obj.get("imagePullSecrets") is not None
                    else None
                ),
                "labels": (
                    LabelsDefaults.from_dict(obj["labels"])
                    if obj.get("labels") is not None
                    else None
                ),
                "nodeAffinityRequired": (
                    NodeAffinityRequired.from_dict(obj["nodeAffinityRequired"])
                    if obj.get("nodeAffinityRequired") is not None
                    else None
                ),
                "nodeType": obj.get("nodeType"),
                "podAffinity": (
                    PodAffinity.from_dict(obj["podAffinity"])
                    if obj.get("podAffinity") is not None
                    else None
                ),
                "probes": (
                    Probes.from_dict(obj["probes"])
                    if obj.get("probes") is not None
                    else None
                ),
                "security": (
                    InferencePolicyDefaultsV2AllOfSecurity.from_dict(obj["security"])
                    if obj.get("security") is not None
                    else None
                ),
                "storage": (
                    DistributedInferenceLeaderWorkerDefaultsV2Storage.from_dict(
                        obj["storage"]
                    )
                    if obj.get("storage") is not None
                    else None
                ),
                "tolerations": (
                    TolerationsDefaults.from_dict(obj["tolerations"])
                    if obj.get("tolerations") is not None
                    else None
                ),
                "workingDir": obj.get("workingDir"),
            }
        )
        return _obj
