# coding: utf-8

"""
NVIDIA Run:ai

# Introduction  The NVIDIA Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  NVIDIA Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create a **Service account** through the NVIDIA Run:ai user interface. To create a service account, in your UI, go to Access → Service Accounts (for organization-level service accounts) or User settings → Access Keys (for user access keys), and create a new one.  After you have created a new service account, you will need to assign it access rules. To assign access rules to the service account, see [Create access rules](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/accessrules#create-or-delete-rules). Make sure you assign the correct rules to your service account. Use the [Roles](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://run-ai-docs.nvidia.com/saas/reference/api/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


import unittest

import runai
from runai.models.node_info import NodeInfo


class TestNodeInfo(unittest.TestCase):
    """NodeInfo unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> NodeInfo:
        """Test NodeInfo
        include_optional is a boolean, when False only required
        params are included, when True both required and
        optional params are included"""
        # uncomment below to create an instance of `NodeInfo`

        # model = NodeInfo()
        if include_optional:
            return NodeInfo(
                status="Ready",
                conditions=[
                    runai.models.node_status_condition_details.NodeStatusConditionDetails(
                        type="",
                        reason="KubeletNotReady",
                        message="container runtime status check may not have completed yet",
                    )
                ],
                taints=[
                    runai.models.node_taint.NodeTaint(
                        key="foo",
                        value="bar",
                        effect="NoSchedule",
                    )
                ],
                node_pool="node-pool-1",
                created_at=datetime.datetime.strptime(
                    "2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f"
                ),
                gpu_info=runai.models.gpu_info.GpuInfo(
                    gpu_type="Tesla-V100",
                    gpu_count=56,
                ),
                nv_link_domain_uid="nvlink-domain-uid",
                nv_link_clique_id="clique-id",
            )
        else:
            return NodeInfo(
                status="Ready",
                node_pool="node-pool-1",
                created_at=datetime.datetime.strptime(
                    "2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f"
                ),
            )

    def testNodeInfo(self):
        """Test NodeInfo"""
        inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)


if __name__ == "__main__":
    unittest.main()
