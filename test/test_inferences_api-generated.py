# coding: utf-8

"""
Test file for InferencesApi
Generated by OpenAPI Generator with custom template
"""

import pytest
import unittest.mock as mock
from datetime import datetime, timezone
import json

from runai.configuration import Configuration
from runai.api_client import ApiClient
from runai.models import *
from runai.exceptions import ApiException


class TestInferencesApi:
    """Test cases for InferencesApi"""

    @pytest.fixture(autouse=True)
    def setup(self):
        """Setup test fixtures"""
        self.configuration = Configuration(
            client_id="test-client",
            client_secret="test-secret",
            runai_base_url="https://test.run.ai",
        )
        self.api_client = ApiClient(self.configuration)
        self.api = InferencesApi(self.api_client)

        # Mock the request method
        self.request_patcher = mock.patch.object(self.api_client.rest_client, "request")
        self.mock_request = self.request_patcher.start()
        yield
        self.request_patcher.stop()

    def test_create_inference1(self):
        """Test case for create_inference1

        Create an inference. Create an inference using container related fields.
        """
        # Mock response
        mock_response = mock.Mock()
        mock_response.status = 200
        mock_response.read.return_value = json.dumps({"data": {}})
        self.mock_request.return_value = mock_response

        # Test parameters
        inference_creation_request = (
            runai.InferenceCreationRequest()
        )  # InferenceCreationRequest |

        # Make request
        response = self.api.create_inference1()

        # Verify request was made
        assert self.mock_request.called
        args, kwargs = self.mock_request.call_args

        # Verify request method and URL
        assert kwargs["method"] == "POST"
        assert "/api/v1/workloads/inferences" in kwargs["url"]

        # Verify body
        assert kwargs["body"] is not None

        # Verify response
        assert isinstance(response, Inference1)

    def test_create_inference1_error(self):
        """Test error handling for create_inference1"""
        # Mock error response
        mock_response = mock.Mock()
        mock_response.status = 400
        mock_response.read.return_value = json.dumps({"message": "Error message"})
        self.mock_request.return_value = mock_response

        # Test parameters

        # Verify error handling
        with pytest.raises(ApiException) as exc_info:
            self.api.create_inference1()
        assert exc_info.value.status == 400

    def test_delete_inference(self):
        """Test case for delete_inference

        Delete an inference. Delete an inference using a workload id.
        """
        # Mock response
        mock_response = mock.Mock()
        mock_response.status = 200
        mock_response.read.return_value = json.dumps({})
        self.mock_request.return_value = mock_response

        # Test parameters
        workload_id = "workload_id_example"  # str | The  Universally Unique Identifier (UUID) of the workload.

        # Make request
        self.api.delete_inference(
            workload_id=workload_id,
        )

        # Verify request was made
        assert self.mock_request.called
        args, kwargs = self.mock_request.call_args

        # Verify request method and URL
        assert kwargs["method"] == "DELETE"
        assert "/api/v1/workloads/inferences/{workloadId}" in kwargs["url"]

    def test_delete_inference_error(self):
        """Test error handling for delete_inference"""
        # Mock error response
        mock_response = mock.Mock()
        mock_response.status = 400
        mock_response.read.return_value = json.dumps({"message": "Error message"})
        self.mock_request.return_value = mock_response

        # Test parameters
        workload_id = "workload_id_example"

        # Verify error handling
        with pytest.raises(ApiException) as exc_info:
            self.api.delete_inference(
                workload_id=workload_id,
            )
        assert exc_info.value.status == 400

    def test_get_inference(self):
        """Test case for get_inference

        Get inference data. Retrieve inference details using a workload id.
        """
        # Mock response
        mock_response = mock.Mock()
        mock_response.status = 200
        mock_response.read.return_value = json.dumps({"data": {}})
        self.mock_request.return_value = mock_response

        # Test parameters
        workload_id = "workload_id_example"  # str | The  Universally Unique Identifier (UUID) of the workload.

        # Make request
        response = self.api.get_inference(
            workload_id=workload_id,
        )

        # Verify request was made
        assert self.mock_request.called
        args, kwargs = self.mock_request.call_args

        # Verify request method and URL
        assert kwargs["method"] == "GET"
        assert "/api/v1/workloads/inferences/{workloadId}" in kwargs["url"]

        # Verify response
        assert isinstance(response, Inference1)

    def test_get_inference_error(self):
        """Test error handling for get_inference"""
        # Mock error response
        mock_response = mock.Mock()
        mock_response.status = 400
        mock_response.read.return_value = json.dumps({"message": "Error message"})
        self.mock_request.return_value = mock_response

        # Test parameters
        workload_id = "workload_id_example"

        # Verify error handling
        with pytest.raises(ApiException) as exc_info:
            self.api.get_inference(
                workload_id=workload_id,
            )
        assert exc_info.value.status == 400

    def test_get_inference_workload_metrics(self):
        """Test case for get_inference_workload_metrics

        Get inference metrics data. Retrieve inference metrics data by id. Supported from control-plane version 2.18 or later.
        """
        # Mock response
        mock_response = mock.Mock()
        mock_response.status = 200
        mock_response.read.return_value = json.dumps({"data": {}})
        self.mock_request.return_value = mock_response

        # Test parameters
        workload_id = "workload_id_example"  # str | The  Universally Unique Identifier (UUID) of the workload.
        metric_type = [
            runai.InferenceWorkloadMetricType()
        ]  # List[InferenceWorkloadMetricType] | Specify which data to request.
        start = "2023-06-06T12:09:18.211Z"  # datetime | Start date of time range to fetch data in ISO 8601 timestamp format.
        end = "2023-06-07T12:09:18.211Z"  # datetime | End date of time range to fetch data in ISO 8601 timestamp format.
        number_of_samples = (
            20  # int | The number of samples to take in the specified time range.
        )

        # Make request
        response = self.api.get_inference_workload_metrics(
            workload_id=workload_id,
            metric_type=metric_type,
            start=start,
            end=end,
        )

        # Verify request was made
        assert self.mock_request.called
        args, kwargs = self.mock_request.call_args

        # Verify request method and URL
        assert kwargs["method"] == "GET"
        assert "/api/v1/workloads/inferences/{workloadId}/metrics" in kwargs["url"]

        # Verify query parameters
        assert "metricType=" in kwargs["url"]
        # Verify query parameters
        assert "start=" in kwargs["url"]
        # Verify query parameters
        assert "end=" in kwargs["url"]
        # Verify query parameters
        assert "numberOfSamples=" in kwargs["url"]

        # Verify response
        assert isinstance(response, MetricsResponse)

    def test_get_inference_workload_metrics_error(self):
        """Test error handling for get_inference_workload_metrics"""
        # Mock error response
        mock_response = mock.Mock()
        mock_response.status = 400
        mock_response.read.return_value = json.dumps({"message": "Error message"})
        self.mock_request.return_value = mock_response

        # Test parameters
        workload_id = "workload_id_example"
        metric_type = [runai.InferenceWorkloadMetricType()]
        start = "2023-06-06T12:09:18.211Z"
        end = "2023-06-07T12:09:18.211Z"

        # Verify error handling
        with pytest.raises(ApiException) as exc_info:
            self.api.get_inference_workload_metrics(
                workload_id=workload_id,
                metric_type=metric_type,
                start=start,
                end=end,
            )
        assert exc_info.value.status == 400

    def test_get_inference_workload_pod_metrics(self):
        """Test case for get_inference_workload_pod_metrics

        Get inference pod's metrics data. Retrieve inference metrics pod&#39;s data by workload and pod id. Supported from control-plane version 2.18 or later.
        """
        # Mock response
        mock_response = mock.Mock()
        mock_response.status = 200
        mock_response.read.return_value = json.dumps({"data": {}})
        self.mock_request.return_value = mock_response

        # Test parameters
        workload_id = "workload_id_example"  # str | The  Universally Unique Identifier (UUID) of the workload.
        pod_id = "pod_id_example"  # str | The requested pod id.
        metric_type = [
            runai.InferencePodMetricType()
        ]  # List[InferencePodMetricType] | Specifies metrics data to request. Inference metrics are only available for inference workloads.
        start = "2023-06-06T12:09:18.211Z"  # datetime | Start date of time range to fetch data in ISO 8601 timestamp format.
        end = "2023-06-07T12:09:18.211Z"  # datetime | End date of time range to fetch data in ISO 8601 timestamp format.
        number_of_samples = (
            20  # int | The number of samples to take in the specified time range.
        )

        # Make request
        response = self.api.get_inference_workload_pod_metrics(
            workload_id=workload_id,
            pod_id=pod_id,
            metric_type=metric_type,
            start=start,
            end=end,
        )

        # Verify request was made
        assert self.mock_request.called
        args, kwargs = self.mock_request.call_args

        # Verify request method and URL
        assert kwargs["method"] == "GET"
        assert (
            "/api/v1/workloads/inferences/{workloadId}/pods/{podId}/metrics"
            in kwargs["url"]
        )

        # Verify query parameters
        assert "metricType=" in kwargs["url"]
        # Verify query parameters
        assert "start=" in kwargs["url"]
        # Verify query parameters
        assert "end=" in kwargs["url"]
        # Verify query parameters
        assert "numberOfSamples=" in kwargs["url"]

        # Verify response
        assert isinstance(response, MetricsResponse)

    def test_get_inference_workload_pod_metrics_error(self):
        """Test error handling for get_inference_workload_pod_metrics"""
        # Mock error response
        mock_response = mock.Mock()
        mock_response.status = 400
        mock_response.read.return_value = json.dumps({"message": "Error message"})
        self.mock_request.return_value = mock_response

        # Test parameters
        workload_id = "workload_id_example"
        pod_id = "pod_id_example"
        metric_type = [runai.InferencePodMetricType()]
        start = "2023-06-06T12:09:18.211Z"
        end = "2023-06-07T12:09:18.211Z"

        # Verify error handling
        with pytest.raises(ApiException) as exc_info:
            self.api.get_inference_workload_pod_metrics(
                workload_id=workload_id,
                pod_id=pod_id,
                metric_type=metric_type,
                start=start,
                end=end,
            )
        assert exc_info.value.status == 400

    def test_update_inference_spec(self):
        """Test case for update_inference_spec

        Update inference spec. [Experimental] Update the specification of an existing inference workload.
        """
        # Mock response
        mock_response = mock.Mock()
        mock_response.status = 200
        mock_response.read.return_value = json.dumps({"data": {}})
        self.mock_request.return_value = mock_response

        # Test parameters
        workload_id = "workload_id_example"  # str | The  Universally Unique Identifier (UUID) of the workload.
        inference_update_request = (
            runai.InferenceUpdateRequest()
        )  # InferenceUpdateRequest |

        # Make request
        response = self.api.update_inference_spec(
            workload_id=workload_id,
        )

        # Verify request was made
        assert self.mock_request.called
        args, kwargs = self.mock_request.call_args

        # Verify request method and URL
        assert kwargs["method"] == "PATCH"
        assert "/api/v1/workloads/inferences/{workloadId}" in kwargs["url"]

        # Verify body
        assert kwargs["body"] is not None

        # Verify response
        assert isinstance(response, Inference1)

    def test_update_inference_spec_error(self):
        """Test error handling for update_inference_spec"""
        # Mock error response
        mock_response = mock.Mock()
        mock_response.status = 400
        mock_response.read.return_value = json.dumps({"message": "Error message"})
        self.mock_request.return_value = mock_response

        # Test parameters
        workload_id = "workload_id_example"

        # Verify error handling
        with pytest.raises(ApiException) as exc_info:
            self.api.update_inference_spec(
                workload_id=workload_id,
            )
        assert exc_info.value.status == 400
