# coding: utf-8

"""
NVIDIA Run:ai

# Introduction  The NVIDIA Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  NVIDIA Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create an **Application** through the NVIDIA Run:ai user interface. To create an application, in your UI, go to `Settings & Tools`, `Application` and create a new Application.  After you have created a new application, you will need to assign it access rules. To assign access rules to the application, see [Create access rules](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/accessrules#create-or-delete-rules). Make sure you assign the correct rules to your application. Use the [Roles](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://run-ai-docs.nvidia.com/saas/reference/api/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


import unittest

import runai
from runai.models.distributed_inference_common_rules_v2 import (
    DistributedInferenceCommonRulesV2,
)


class TestDistributedInferenceCommonRulesV2(unittest.TestCase):
    """DistributedInferenceCommonRulesV2 unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> DistributedInferenceCommonRulesV2:
        """Test DistributedInferenceCommonRulesV2
        include_optional is a boolean, when False only required
        params are included, when True both required and
        optional params are included"""
        # uncomment below to create an instance of `DistributedInferenceCommonRulesV2`

        # model = DistributedInferenceCommonRulesV2()
        if include_optional:
            return DistributedInferenceCommonRulesV2(
                startup_policy=runai.models.distributed_inference_startup_policy_field_rules_startup_policy.DistributedInferenceStartupPolicyFieldRules_startupPolicy(),
                workers=runai.models.integer_rules.IntegerRules(
                    source_of_rule={"scope": "project", "projectId": 3},
                    required=True,
                    can_edit=True,
                    min=56,
                    max=56,
                    step=56,
                    default_from=runai.models.default_from_rule.DefaultFromRule(
                        field="jUR,rZ#UM/?R,Fp^l6$ARj",
                        factor=1.337,
                    ),
                ),
                replicas=runai.models.integer_rules.IntegerRules(
                    source_of_rule={"scope": "project", "projectId": 3},
                    required=True,
                    can_edit=True,
                    min=56,
                    max=56,
                    step=56,
                    default_from=runai.models.default_from_rule.DefaultFromRule(
                        field="jUR,rZ#UM/?R,Fp^l6$ARj",
                        factor=1.337,
                    ),
                ),
                category=runai.models.string_rules.StringRules(),
                node_pools=runai.models.array_rules.ArrayRules(
                    source_of_rule={"scope": "project", "projectId": 3},
                    required=True,
                    options=[
                        {"value": "value", "displayed": "A description of the value."}
                    ],
                    can_edit=True,
                ),
                priority_class=runai.models.string_rules.StringRules(),
                restart_policy=runai.models.distributed_inference_restart_policy_rules.DistributedInferenceRestartPolicyRules(),
                serving_port=runai.models.distributed_inference_serving_port_rules_2.DistributedInferenceServingPortRules
                - 2(),
            )
        else:
            return DistributedInferenceCommonRulesV2()

    def testDistributedInferenceCommonRulesV2(self):
        """Test DistributedInferenceCommonRulesV2"""
        inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)


if __name__ == "__main__":
    unittest.main()
