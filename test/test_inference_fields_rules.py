# coding: utf-8

"""
NVIDIA Run:ai

# Introduction  The NVIDIA Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  NVIDIA Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create a **Service account** through the NVIDIA Run:ai user interface. To create a service account, in your UI, go to Access → Service Accounts (for organization-level service accounts) or User settings → Access Keys (for user access keys), and create a new one.  After you have created a new service account, you will need to assign it access rules. To assign access rules to the service account, see [Create access rules](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/accessrules#create-or-delete-rules). Make sure you assign the correct rules to your service account. Use the [Roles](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://run-ai-docs.nvidia.com/saas/reference/api/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


import unittest

import runai
from runai.models.inference_fields_rules import InferenceFieldsRules


class TestInferenceFieldsRules(unittest.TestCase):
    """InferenceFieldsRules unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> InferenceFieldsRules:
        """Test InferenceFieldsRules
        include_optional is a boolean, when False only required
        params are included, when True both required and
        optional params are included"""
        # uncomment below to create an instance of `InferenceFieldsRules`

        # model = InferenceFieldsRules()
        if include_optional:
            return InferenceFieldsRules(
                autoscaling=runai.models.auto_scaling_rules.AutoScalingRules(
                    metric_threshold_percentage=runai.models.number_rules.NumberRules(
                        source_of_rule={"scope": "project", "projectId": 3},
                        required=True,
                        can_edit=True,
                        min=1.337,
                        max=1.337,
                        step=1.337,
                        default_from=runai.models.default_from_rule.DefaultFromRule(
                            field="jUR,rZ#UM/?R,Fp^l6$ARj",
                            factor=1.337,
                        ),
                    ),
                    min_replicas=runai.models.integer_rules.IntegerRules(
                        required=True,
                        can_edit=True,
                        min=56,
                        max=56,
                        step=56,
                    ),
                    max_replicas=runai.models.integer_rules.IntegerRules(
                        required=True,
                        can_edit=True,
                        min=56,
                        max=56,
                        step=56,
                    ),
                    initial_replicas=None,
                    activation_replicas=None,
                    metric=runai.models.auto_scaling_metric_rules.AutoScalingMetricRules(),
                    metric_threshold=None,
                    concurrency_hard_limit=None,
                    scale_to_zero_retention_seconds=None,
                    scale_down_delay_seconds=None,
                    initialization_timeout_seconds=None,
                ),
                serving_configuration=runai.models.serving_configuration_rules.ServingConfigurationRules(
                    initialization_timeout_seconds=runai.models.integer_rules.IntegerRules(
                        source_of_rule={"scope": "project", "projectId": 3},
                        required=True,
                        can_edit=True,
                        min=56,
                        max=56,
                        step=56,
                        default_from=runai.models.default_from_rule.DefaultFromRule(
                            field="jUR,rZ#UM/?R,Fp^l6$ARj",
                            factor=1.337,
                        ),
                    ),
                    request_timeout_seconds=runai.models.integer_rules.IntegerRules(
                        required=True,
                        can_edit=True,
                        min=56,
                        max=56,
                        step=56,
                    ),
                ),
            )
        else:
            return InferenceFieldsRules()

    def testInferenceFieldsRules(self):
        """Test InferenceFieldsRules"""
        inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)


if __name__ == "__main__":
    unittest.main()
