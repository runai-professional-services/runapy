# coding: utf-8

"""
Run:ai API

# Introduction  The Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create an **Application** through the Run:ai user interface. To create an application, in your UI, go to `Settings & Tools`, `Application` and create a new Application.  After you have created a new application, you will need to assign it access rules. To assign access rules to the application, see [Create access rules](https://docs.run.ai/latest/admin/runai-setup/access-control/rbac/?h=create+delete+app#create-or-delete-rules). Make sure you assign the correct rules to your application. Use the [Roles](https://docs.run.ai/latest/admin/runai-setup/access-control/rbac/?h=create+delete+app#roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://docs.run.ai/latest/developer/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


import unittest

import runai
from runai.models.revision import Revision


class TestRevision(unittest.TestCase):
    """Revision unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> Revision:
        """Test Revision
        include_optional is a boolean, when False only required
        params are included, when True both required and
        optional params are included"""
        # uncomment below to create an instance of `Revision`

        # model = Revision()
        if include_optional:
            return Revision(
                type="runai-revision",
                name="very-important-job",
                id="",
                workload_id="",
                tenant_id=1001,
                cluster_id="71f69d83-ba66-4822-adf5-55ce55efd210",
                project_id="1",
                department_id="2",
                created_at="2022-01-01T03:49:52.531Z",
                deleted_at="2022-08-12T19:28:24.131Z",
                revision_requested_resources=runai.models.workload_request_resources.WorkloadRequestResources(
                    gpu_request_type="portion",
                    gpu=runai.models.request_resource_cores.RequestResourceCores(
                        limit=1.5,
                        request=1,
                    ),
                    gpu_memory=runai.models.request_resource_quantity.RequestResourceQuantity(
                        limit="2G",
                        request="200M",
                    ),
                    cpu=runai.models.request_resource_cores.RequestResourceCores(
                        limit=1.5,
                        request=1,
                    ),
                    cpu_memory=runai.models.request_resource_quantity.RequestResourceQuantity(
                        limit="2G",
                        request="200M",
                    ),
                    mig_profile=["1g.5gb"],
                    extended_resources=[
                        runai.models.workloads_extended_resource.WorkloadsExtendedResource(
                            resource="hardware-vendor.example/foo",
                            quantity="2",
                            exclude=False,
                        )
                    ],
                ),
                pods_requested_resources=runai.models.workload_request_resources.WorkloadRequestResources(
                    gpu_request_type="portion",
                    gpu=runai.models.request_resource_cores.RequestResourceCores(
                        limit=1.5,
                        request=1,
                    ),
                    gpu_memory=runai.models.request_resource_quantity.RequestResourceQuantity(
                        limit="2G",
                        request="200M",
                    ),
                    cpu=runai.models.request_resource_cores.RequestResourceCores(
                        limit=1.5,
                        request=1,
                    ),
                    cpu_memory=runai.models.request_resource_quantity.RequestResourceQuantity(
                        limit="2G",
                        request="200M",
                    ),
                    mig_profile=["1g.5gb"],
                    extended_resources=[
                        runai.models.workloads_extended_resource.WorkloadsExtendedResource(
                            resource="hardware-vendor.example/foo",
                            quantity="2",
                            exclude=False,
                        )
                    ],
                ),
                requested_pods=runai.models.requested_pods.RequestedPods(
                    number=1,
                    min=2,
                    max=5,
                    parallelism=3,
                    completions=5,
                ),
                requested_node_pools=["default"],
                allocated_resources=runai.models.workload_allocated_resources.WorkloadAllocatedResources(
                    gpu=1.5,
                    mig_profile=["1g.5gb"],
                    gpu_memory="200Mi",
                    cpu=0.5,
                    cpu_memory="0B",
                    extended_resources=[
                        runai.models.workloads_extended_resource.WorkloadsExtendedResource(
                            resource="hardware-vendor.example/foo",
                            quantity="2",
                            exclude=False,
                        )
                    ],
                ),
                current_node_pools=["default"],
                running_pods=1,
                images=["alpine:latest"],
                environment_variables={"key' : '"},
                command="sleep",
                arguments="1000",
                children_ids=[
                    runai.models.workload_children_ids_inner.Workload_childrenIds_inner(
                        id="",
                        type="",
                    )
                ],
                conditions=[
                    runai.models.condition1.Condition1(
                        type="Ready",
                        status="False",
                        message="Resource validation failed: ...",
                        reason="ErrorConfig",
                        last_transition_time="2022-01-01T03:49:52.531Z",
                    )
                ],
                phase="Creating",
                phase_message="Not enough resources in the requested nodepool",
                phase_updated_at="2022-06-08T11:28:24.131Z",
                additional_fields={},
            )
        else:
            return Revision(
                type="runai-revision",
                name="very-important-job",
                id="",
                workload_id="",
                tenant_id=1001,
                cluster_id="71f69d83-ba66-4822-adf5-55ce55efd210",
                project_id="1",
                department_id="2",
                created_at="2022-01-01T03:49:52.531Z",
                phase="Creating",
            )

    def testRevision(self):
        """Test Revision"""
        inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)


if __name__ == "__main__":
    unittest.main()
