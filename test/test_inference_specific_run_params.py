# coding: utf-8

"""
NVIDIA Run:ai

# Introduction  The NVIDIA Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  NVIDIA Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create an **Application** through the NVIDIA Run:ai user interface. To create an application, in your UI, go to `Settings & Tools`, `Application` and create a new Application.  After you have created a new application, you will need to assign it access rules. To assign access rules to the application, see [Create access rules](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/accessrules#create-or-delete-rules). Make sure you assign the correct rules to your application. Use the [Roles](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://run-ai-docs.nvidia.com/saas/reference/api/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


import unittest

import runai
from runai.models.inference_specific_run_params import InferenceSpecificRunParams


class TestInferenceSpecificRunParams(unittest.TestCase):
    """InferenceSpecificRunParams unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> InferenceSpecificRunParams:
        """Test InferenceSpecificRunParams
        include_optional is a boolean, when False only required
        params are included, when True both required and
        optional params are included"""
        # uncomment below to create an instance of `InferenceSpecificRunParams`

        # model = InferenceSpecificRunParams()
        if include_optional:
            return InferenceSpecificRunParams(
                connections=[
                    runai.models.specific_run_connection_info.SpecificRunConnectionInfo(
                        name="0",
                        node_port=0,
                        external_url="0",
                        authorized_users=[""],
                        authorized_groups=[""],
                    )
                ],
                auto_scaling=runai.models.specific_run_auto_scaling_auto_scaling.SpecificRunAutoScaling_autoScaling(),
                serving_port_access=runai.models.serving_port_access.ServingPortAccess(
                    authorization_type="public",
                    authorized_users=["user.a@example.com", "user.b@example.com"],
                    authorized_groups=["group-a", "group-b"],
                    cluster_local_access_only=True,
                ),
                annotations=[
                    runai.models.annotation.Annotation(
                        name="billing",
                        value="my-billing-unit",
                        exclude=False,
                    )
                ],
                args="-x my-script.py",
                auto_deletion_time_after_completion_seconds=15,
                backoff_limit=3,
                category="jUR,rZ#UM/?R,Fp^l6$ARj",
                command="python",
                environment_variables=[
                    runai.models.environment_variable_of_asset.EnvironmentVariableOfAsset(
                        name="HOME",
                        value="/home/my-folder",
                        credential=runai.models.environment_variable_credential.EnvironmentVariableCredential(
                            asset_id="0",
                            key="POSTGRES_PASSWORD",
                        ),
                        config_map=runai.models.environment_variable_config_map.EnvironmentVariableConfigMap(
                            name="my-config-map",
                            key="MY_POSTGRES_SCHEMA",
                        ),
                        pod_field_ref=runai.models.environment_variable_pod_field_reference.EnvironmentVariablePodFieldReference(
                            path="metadata.name",
                        ),
                        exclude=False,
                        description="Home directory of the user.",
                    )
                ],
                image_pull_secrets=[
                    runai.models.image_pull_secret.ImagePullSecret(
                        name="w1c2v7s6djuy1zmetozkhdomha1bae37b8ocvx8o53ow2eg7p6qw9qklp6l4y010fogx",
                        user_credential=True,
                        exclude=False,
                    )
                ],
                labels=[
                    runai.models.label.Label(
                        name="stage",
                        value="initial-research",
                        exclude=False,
                    )
                ],
                node_affinity_required=runai.models.node_affinity_required.NodeAffinityRequired(
                    node_selector_terms=[
                        runai.models.node_selector_term.NodeSelectorTerm(
                            match_expressions=[
                                runai.models.match_expression.MatchExpression(
                                    key="jUR,rZ#UM/?R,Fp^l6$ARj",
                                    operator="In",
                                    values=["jUR,rZ#UM/?R,Fp^l6$ARj"],
                                )
                            ],
                        )
                    ],
                ),
                node_pools=["my-node-pool-a", "my-node-pool-b"],
                node_type="my-node-type",
                pod_affinity=runai.models.pod_affinity.PodAffinity(
                    type="Required",
                    key="jUR,rZ#UM/?R,Fp^l6$ARj",
                ),
                priority_class="jUR,rZ#UM/?R,Fp^l6$ARj",
                restart_policy="Always",
                run_as_gid=30,
                run_as_uid=500,
                supplemental_groups="2,3,5,8",
                terminate_after_preemption=False,
                termination_grace_period_seconds=20,
                tolerations=[
                    runai.models.toleration.Toleration(
                        name="jUR,rZ#UM/?R,Fp^l6$ARj0",
                        operator="Equal",
                        key="jUR,rZ#UM/?R,Fp^l6$ARj",
                        value="jUR,rZ#UM/?R,Fp^l6$ARj",
                        effect="NoSchedule",
                        seconds=1,
                        exclude=False,
                    )
                ],
            )
        else:
            return InferenceSpecificRunParams()

    def testInferenceSpecificRunParams(self):
        """Test InferenceSpecificRunParams"""
        inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)


if __name__ == "__main__":
    unittest.main()
